# name: test/sql/copy/s3/s3_hive_partition.test
# description: Test the automatic parsing of the hive partitioning scheme
# group: [s3]

require parquet

require httpfs

require-env S3_TEST_SERVER_AVAILABLE 1

# override the default behaviour of skipping HTTP errors and connection failures: this test fails on connection issues
set ignore_error_messages

statement ok
SET s3_secret_access_key='minio_duckdb_user_password';SET s3_access_key_id='minio_duckdb_user';SET s3_region='eu-west-1'; SET s3_endpoint='duckdb-minio.com:9000';SET s3_use_ssl=false;

# Parquet filename name conflict
statement ok
CREATE TABLE test AS SELECT 1 as id, 'value1' as value;
CREATE TABLE test2 AS SELECT 2 as id, 'value2' as value;

statement ok
COPY test TO 's3://test-bucket/hive-partitioning/simple/key_!-_.*()=zisiswurking1/test.parquet';
COPY test2 TO 's3://test-bucket/hive-partitioning/simple/key_!-_.*()=zisiswurking2/test.parquet';

# test parsing hive partitioning scheme, with some common special characters
query III
select id, value, "key_!-_.*()" from parquet_scan('s3://test-bucket/hive-partitioning/simple/*/test.parquet', HIVE_PARTITIONING=1)
----
1	value1	zisiswurking1
2	value2	zisiswurking2