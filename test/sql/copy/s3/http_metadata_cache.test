# name: test/sql/copy/s3/http_metadata_cache.test
# description: Test metadata cache option
# group: [s3]

require parquet

require httpfs

require-env S3_TEST_SERVER_AVAILABLE 1

# override the default behaviour of skipping HTTP errors and connection failures: this test fails on connection issues
set ignore_error_messages

# Long timeout should last us throughout the test
statement ok
SET http_metadata_cache_max_age=200000

### Simple copy/scan file
statement ok
CREATE TABLE test as SELECT * FROM range(0,10) tbl(i);

statement ok
SET s3_secret_access_key='minio_duckdb_user_password';SET s3_access_key_id='minio_duckdb_user';SET s3_region='eu-west-1'; SET s3_endpoint='duckdb-minio.com:9000'; SET s3_use_ssl=false;

statement ok
COPY test TO 's3://test-bucket/root-dir/http_metadata_cache/test.parquet';

query I
SELECT sum(i) FROM 's3://test-bucket/root-dir/http_metadata_cache/test.parquet';
----
45

### overwrite same file with bigger one
statement ok
CREATE TABLE test2 as SELECT * FROM range(0,20) tbl(i);

statement ok
COPY test2 TO 's3://test-bucket/root-dir/http_metadata_cache/test.parquet';

query I
SELECT sum(i) FROM 's3://test-bucket/root-dir/http_metadata_cache/test.parquet';
----
190

### Write with cache disabled, then reenable and read again
statement ok
SET http_metadata_cache_max_age=0

statement ok
CREATE TABLE test3 as SELECT * FROM range(0,30) tbl(i);

statement ok
COPY test3 TO 's3://test-bucket/root-dir/http_metadata_cache/test.parquet';

statement ok
SET http_metadata_cache_max_age=200000

query I
SELECT sum(i) FROM 's3://test-bucket/root-dir/http_metadata_cache/test.parquet';
----
435