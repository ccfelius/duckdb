# name: test/sql/copy/hive_partitioned_write.test_slow
# description: slow test for the hive partitioned write
# group: [copy]

require parquet

require tpch

statement ok
pragma memory_limit='100mb'

# around 200MB worth of data, will require the PartitionedColumnData to spill to disk
statement ok
COPY (SELECT i%2::INT32 as part_col, i::INT32 FROM range(0,25000000) tbl(i)) TO '__TEST_DIR__/partitioned_memory_spill' (FORMAT parquet, PARTITION_BY part_col);

statement ok
pragma memory_limit='-1'

statement ok
call dbgen(sf=1);

# Partition by 2 columns
statement ok
COPY lineitem TO '__TEST_DIR__/lineitem_sf1_partitioned' (FORMAT PARQUET, PARTITION_BY (l_returnflag, l_linestatus));

statement ok
DROP TABLE lineitem;

statement ok
CREATE VIEW lineitem as SELECT * FROM '__TEST_DIR__/lineitem_sf1_partitioned/*/*/*.parquet';

query I
pragma tpch(6);
----
123141078.2283

statement ok
pragma threads=8;

# threads x partitions = 8 x 4 = 16
query I
SELECT COUNT(DISTINCT filename) FROM parquet_scan('__TEST_DIR__/lineitem_sf1_partitioned/*/*/*.parquet', filename=1);
----
32
