# name: test/sql/function/string/test_tokenize.test
# description: Tokenize test
# group: [string]

statement ok
PRAGMA enable_verification

query T
SELECT UNNEST(tokenize('🦆 🦆 🦆 🦆 🦆'))
----
🦆
🦆
🦆
🦆
🦆

statement ok
CREATE TABLE documents(s VARCHAR)

statement ok
INSERT INTO documents VALUES ('  Hello, World!  '), ('helloworld'), (''), ('  Ĥéĺĺó, Ŵóŕĺɗ!  '), ('🦆 🦆 🦆 🦆 🦆')

query T
SELECT UNNEST(tokenize(s)) FROM documents
----
Hello,
World!
helloworld
Ĥéĺĺó,
Ŵóŕĺɗ!
🦆
🦆
🦆
🦆
🦆

statement ok
SELECT tokenize(string_agg(range, ' ')), mod(range, 10000) xx FROM range(100000) GROUP BY xx
----

query T
SELECT UNNEST(tokenize(NULL))
----
NULL

# TODO: add where clause, constants, a million strings, and full circle with concat