diff --git a/CMakeLists.txt b/CMakeLists.txt
index 9a8d39b..c1298e1 100644
--- a/CMakeLists.txt
+++ b/CMakeLists.txt
@@ -14,6 +14,7 @@ build_static_extension(
   extension/httpfs/hffs.cpp
   extension/httpfs/s3fs.cpp
   extension/httpfs/httpfs.cpp
+        extension/httpfs/httpfs_client.cpp
   extension/httpfs/http_state.cpp
   extension/httpfs/crypto.cpp
   extension/httpfs/create_secret_functions.cpp
diff --git a/extension/httpfs/crypto.cpp b/extension/httpfs/crypto.cpp
index af56f11..bd01f40 100644
--- a/extension/httpfs/crypto.cpp
+++ b/extension/httpfs/crypto.cpp
@@ -4,8 +4,47 @@
 #include "duckdb/common/common.hpp"
 #include <stdio.h>
 
-#define CPPHTTPLIB_OPENSSL_SUPPORT
-#include "httplib.hpp"
+// FIXME: this is copied from httplib.hpp
+#ifdef _WIN32
+#include <wincrypt.h>
+
+// these are defined in wincrypt.h and it breaks compilation if BoringSSL is
+// used
+#undef X509_NAME
+#undef X509_CERT_PAIR
+#undef X509_EXTENSIONS
+#undef PKCS7_SIGNER_INFO
+
+#ifdef _MSC_VER
+#pragma comment(lib, "crypt32.lib")
+#endif
+#elif defined(CPPHTTPLIB_USE_CERTS_FROM_MACOSX_KEYCHAIN) && defined(__APPLE__)
+#include <TargetConditionals.h>
+#if TARGET_OS_OSX
+#include <CoreFoundation/CoreFoundation.h>
+#include <Security/Security.h>
+#endif // TARGET_OS_OSX
+#endif // _WIN32
+
+#include <openssl/err.h>
+#include <openssl/evp.h>
+#include <openssl/ssl.h>
+#include <openssl/x509v3.h>
+#include <openssl/rand.h>
+
+#if defined(_WIN32) && defined(OPENSSL_USE_APPLINK)
+#include <openssl/applink.c>
+#endif
+
+#include <iostream>
+#include <sstream>
+
+// Disabled OpenSSL version check for CI
+//#if OPENSSL_VERSION_NUMBER < 0x1010100fL
+//#error Sorry, OpenSSL versions prior to 1.1.1 are not supported
+#if OPENSSL_VERSION_NUMBER < 0x30000000L
+#define SSL_get1_peer_certificate SSL_get_peer_certificate
+#endif
 
 namespace duckdb {
 
@@ -31,68 +70,82 @@ void hex256(hash_bytes &in, hash_str &out) {
 	}
 }
 
-const EVP_CIPHER *GetCipher(const string &key) {
-	// For now, we only support GCM ciphers
-	switch (key.size()) {
-	case 16:
-		return EVP_aes_128_gcm();
-	case 24:
-		return EVP_aes_192_gcm();
-	case 32:
-		return EVP_aes_256_gcm();
-	default:
-		throw InternalException("Invalid AES key length");
-	}
-}
-
-AESGCMStateSSL::AESGCMStateSSL() : gcm_context(EVP_CIPHER_CTX_new()) {
-	if (!(gcm_context)) {
+AESStateSSL::AESStateSSL(const std::string *key) : context(EVP_CIPHER_CTX_new()) {
+	if (!(context)) {
 		throw InternalException("AES GCM failed with initializing context");
 	}
 }
 
-AESGCMStateSSL::~AESGCMStateSSL() {
+AESStateSSL::~AESStateSSL() {
 	// Clean up
-	EVP_CIPHER_CTX_free(gcm_context);
+	EVP_CIPHER_CTX_free(context);
 }
 
-bool AESGCMStateSSL::IsOpenSSL() {
-	return ssl;
+const EVP_CIPHER *AESStateSSL::GetCipher(const string &key) {
+
+  switch (cipher) {
+    case GCM:
+      switch (key.size()) {
+      case 16:
+        return EVP_aes_128_gcm();
+      case 24:
+        return EVP_aes_192_gcm();
+      case 32:
+        return EVP_aes_256_gcm();
+      default:
+        throw InternalException("Invalid AES key length");
+    }
+    case CTR:
+      switch (key.size()) {
+      case 16:
+        return EVP_aes_128_ctr();
+      case 24:
+        return EVP_aes_192_ctr();
+      case 32:
+        return EVP_aes_256_ctr();
+      default:
+        throw InternalException("Invalid AES key length");
+      }
+
+  default:
+    throw duckdb::InternalException("Invalid Encryption/Decryption Cipher: %d",
+                                    static_cast<int>(cipher));
+  }
 }
 
-void AESGCMStateSSL::GenerateRandomData(data_ptr_t data, idx_t len) {
+void AESStateSSL::GenerateRandomData(data_ptr_t data, idx_t len) {
 	// generate random bytes for nonce
 	RAND_bytes(data, len);
 }
 
-void AESGCMStateSSL::InitializeEncryption(const_data_ptr_t iv, idx_t iv_len, const string *key) {
+void AESStateSSL::InitializeEncryption(const_data_ptr_t iv, idx_t iv_len, const string *key) {
 	mode = ENCRYPT;
 
-	if (1 != EVP_EncryptInit_ex(gcm_context, GetCipher(*key), NULL, const_data_ptr_cast(key->data()), iv)) {
+	if (1 != EVP_EncryptInit_ex(context, GetCipher(*key), NULL, const_data_ptr_cast(key->data()), iv)) {
 		throw InternalException("EncryptInit failed");
 	}
 }
 
-void AESGCMStateSSL::InitializeDecryption(const_data_ptr_t iv, idx_t iv_len, const string *key) {
+void AESStateSSL::InitializeDecryption(const_data_ptr_t iv, idx_t iv_len, const string *key) {
 	mode = DECRYPT;
 
-	if (1 != EVP_DecryptInit_ex(gcm_context, GetCipher(*key), NULL, const_data_ptr_cast(key->data()), iv)) {
+	if (1 != EVP_DecryptInit_ex(context, GetCipher(*key), NULL, const_data_ptr_cast(key->data()), iv)) {
 		throw InternalException("DecryptInit failed");
 	}
 }
 
-size_t AESGCMStateSSL::Process(const_data_ptr_t in, idx_t in_len, data_ptr_t out, idx_t out_len) {
+size_t AESStateSSL::Process(const_data_ptr_t in, idx_t in_len, data_ptr_t out, idx_t out_len) {
 
 	switch (mode) {
 	case ENCRYPT:
-		if (1 != EVP_EncryptUpdate(gcm_context, data_ptr_cast(out), reinterpret_cast<int *>(&out_len),
+		if (1 != EVP_EncryptUpdate(context, data_ptr_cast(out), reinterpret_cast<int *>(&out_len),
 		                           const_data_ptr_cast(in), (int)in_len)) {
 			throw InternalException("EncryptUpdate failed");
 		}
 		break;
 
 	case DECRYPT:
-		if (1 != EVP_DecryptUpdate(gcm_context, data_ptr_cast(out), reinterpret_cast<int *>(&out_len),
+		if (1 != EVP_DecryptUpdate(context, data_ptr_cast(out), reinterpret_cast<int *>(&out_len),
 		                           const_data_ptr_cast(in), (int)in_len)) {
 
 			throw InternalException("DecryptUpdate failed");
@@ -107,41 +160,79 @@ size_t AESGCMStateSSL::Process(const_data_ptr_t in, idx_t in_len, data_ptr_t out
 	return out_len;
 }
 
-size_t AESGCMStateSSL::Finalize(data_ptr_t out, idx_t out_len, data_ptr_t tag, idx_t tag_len) {
-	auto text_len = out_len;
+size_t AESStateSSL::FinalizeGCM(data_ptr_t out, idx_t out_len, data_ptr_t tag, idx_t tag_len){
+    auto text_len = out_len;
+
+    switch (mode) {
+        case ENCRYPT:
+        {
+            if (1 != EVP_EncryptFinal_ex(context, data_ptr_cast(out) + out_len, reinterpret_cast<int *>(&out_len))) {
+                throw InternalException("EncryptFinal failed");
+            }
+            text_len += out_len;
+
+            // The computed tag is written at the end of a chunk
+            if (1 != EVP_CIPHER_CTX_ctrl(context, EVP_CTRL_GCM_GET_TAG, tag_len, tag)) {
+                throw InternalException("Calculating the tag failed");
+            }
+            return text_len;
+        }
+        case DECRYPT:
+        {
+            // Set expected tag value
+            if (!EVP_CIPHER_CTX_ctrl(context, EVP_CTRL_GCM_SET_TAG, tag_len, tag)) {
+                throw InternalException("Finalizing tag failed");
+            }
+
+            // EVP_DecryptFinal() will return an error code if final block is not correctly formatted.
+            int ret = EVP_DecryptFinal_ex(context, data_ptr_cast(out) + out_len, reinterpret_cast<int *>(&out_len));
+            text_len += out_len;
+
+            if (ret > 0) {
+                // success
+                return text_len;
+            }
+            throw InvalidInputException("Computed AES tag differs from read AES tag, are you using the right key?");
+        }
+        default:
+            throw InternalException("Unhandled encryption mode %d", static_cast<int>(mode));
+    }
+}
 
-	switch (mode) {
-	case ENCRYPT:
-	{
-		if (1 != EVP_EncryptFinal_ex(gcm_context, data_ptr_cast(out) + out_len, reinterpret_cast<int *>(&out_len))) {
-			throw InternalException("EncryptFinal failed");
-		}
-		text_len += out_len;
-		// The computed tag is written at the end of a chunk
-		if (1 != EVP_CIPHER_CTX_ctrl(gcm_context, EVP_CTRL_GCM_GET_TAG, tag_len, tag)) {
-			throw InternalException("Calculating the tag failed");
-		}
-		return text_len;
-	}
-	case DECRYPT:
-	{
-		// Set expected tag value
-		if (!EVP_CIPHER_CTX_ctrl(gcm_context, EVP_CTRL_GCM_SET_TAG, tag_len, tag)) {
-			throw InternalException("Finalizing tag failed");
-		}
-		// EVP_DecryptFinal() will return an error code if final block is not correctly formatted.
-		int ret = EVP_DecryptFinal_ex(gcm_context, data_ptr_cast(out) + out_len, reinterpret_cast<int *>(&out_len));
-		text_len += out_len;
+size_t AESStateSSL::Finalize(data_ptr_t out, idx_t out_len, data_ptr_t tag, idx_t tag_len) {
 
-		if (ret > 0) {
-			// success
-			return text_len;
-		}
-		throw InvalidInputException("Computed AES tag differs from read AES tag, are you using the right key?");
-	}
-	default:
-		throw InternalException("Unhandled encryption mode %d", static_cast<int>(mode));
-	}
+    if (cipher == GCM){
+        return FinalizeGCM(out, out_len, tag, tag_len);
+    }
+
+    auto text_len = out_len;
+    switch (mode) {
+
+    case ENCRYPT:
+    {
+            if (1 != EVP_EncryptFinal_ex(context, data_ptr_cast(out) + out_len, reinterpret_cast<int *>(&out_len))) {
+                    throw InternalException("EncryptFinal failed");
+            }
+
+            return text_len += out_len;
+    }
+
+    case DECRYPT:
+    {
+            // EVP_DecryptFinal() will return an error code if final block is not correctly formatted.
+            int ret = EVP_DecryptFinal_ex(context, data_ptr_cast(out) + out_len, reinterpret_cast<int *>(&out_len));
+            text_len += out_len;
+
+            if (ret > 0) {
+                    // success
+                    return text_len;
+            }
+
+            throw InvalidInputException("Computed AES tag differs from read AES tag, are you using the right key?");
+    }
+    default:
+            throw InternalException("Unhandled encryption mode %d", static_cast<int>(mode));
+    }
 }
 
 } // namespace duckdb
@@ -149,7 +240,7 @@ size_t AESGCMStateSSL::Finalize(data_ptr_t out, idx_t out_len, data_ptr_t tag, i
 extern "C" {
 
 // Call the member function through the factory object
-DUCKDB_EXTENSION_API AESGCMStateSSLFactory *CreateSSLFactory() {
-	return new AESGCMStateSSLFactory();
+DUCKDB_EXTENSION_API AESStateSSLFactory *CreateSSLFactory() {
+	return new AESStateSSLFactory();
 };
 }
diff --git a/extension/httpfs/hffs.cpp b/extension/httpfs/hffs.cpp
index 80b28d6..4566617 100644
--- a/extension/httpfs/hffs.cpp
+++ b/extension/httpfs/hffs.cpp
@@ -12,9 +12,6 @@
 #include <chrono>
 #include <string>
 
-#define CPPHTTPLIB_OPENSSL_SUPPORT
-#include "httplib.hpp"
-
 #include <map>
 
 namespace duckdb {
@@ -47,49 +44,33 @@ static string ParseNextUrlFromLinkHeader(const string &link_header_content) {
 
 HFFileHandle::~HFFileHandle() {};
 
-unique_ptr<duckdb_httplib_openssl::Client> HFFileHandle::CreateClient(optional_ptr<ClientContext> client_context) {
-	return HTTPFileSystem::GetClient(this->http_params, parsed_url.endpoint.c_str(), this);
+unique_ptr<HTTPClient> HFFileHandle::CreateClient() {
+	return http_params.http_util->InitializeClient(http_params, parsed_url.endpoint);
 }
 
-string HuggingFaceFileSystem::ListHFRequest(ParsedHFUrl &url, HTTPParams &http_params, string &next_page_url,
+string HuggingFaceFileSystem::ListHFRequest(ParsedHFUrl &url, HTTPFSParams &http_params, string &next_page_url,
                                             optional_ptr<HTTPState> state) {
-	HeaderMap header_map;
-	auto headers = HTTPFileSystem::InitializeHeaders(header_map, http_params);
+	HTTPHeaders header_map;
 	string link_header_result;
 
-	auto client = HTTPFileSystem::GetClient(http_params, url.endpoint.c_str(), nullptr);
 	std::stringstream response;
-
-	std::function<duckdb_httplib_openssl::Result(void)> request([&]() {
-		if (state) {
-			state->get_count++;
-		}
-
-		return client->Get(
-		    next_page_url.c_str(), *headers,
-		    [&](const duckdb_httplib_openssl::Response &response) {
-			    if (response.status >= 400) {
-				    throw HTTPException(response, "HTTP GET error on '%s' (HTTP %d)", next_page_url, response.status);
-			    }
-			    auto link_res = response.headers.find("Link");
-			    if (link_res != response.headers.end()) {
-				    link_header_result = link_res->second;
-			    }
-			    return true;
-		    },
-		    [&](const char *data, size_t data_length) {
-			    if (state) {
-				    state->total_bytes_received += data_length;
-			    }
-			    response << string(data, data_length);
-			    return true;
-		    });
-	});
-
-	auto res = RunRequestWithRetry(request, next_page_url, "GET", http_params, nullptr);
-
-	if (res->code != 200) {
-		throw IOException(res->error + " error for HTTP GET to '" + next_page_url + "'");
+	GetRequestInfo get_request(url.endpoint, next_page_url, header_map, http_params,
+		[&](const HTTPResponse &response) {
+			if (static_cast<int>(response.status) >= 400) {
+				throw HTTPException(response, "HTTP GET error on '%s' (HTTP %d)", next_page_url, response.status);
+			}
+			if (response.HasHeader("Link")) {
+				link_header_result = response.GetHeaderValue("Link");
+			}
+			return true;
+		},
+		[&](const_data_ptr_t data, idx_t data_length) {
+			response << string(const_char_ptr_cast(data), data_length);
+			return true;
+		});
+	auto res = http_params.http_util->Request(get_request);
+	if (res->status != HTTPStatusCode::OK_200) {
+		throw IOException(res->GetError() + " error for HTTP GET to '" + next_page_url + "'");
 	}
 
 	if (!link_header_result.empty()) {
@@ -223,7 +204,7 @@ vector<OpenFileInfo> HuggingFaceFileSystem::Glob(const string &path, FileOpener
 
 	FileOpenerInfo info;
 	info.file_path = path;
-	auto http_params = HTTPParams::ReadFrom(opener, info);
+	auto http_params = HTTPFSParams::ReadFrom(opener, info);
 	SetParams(http_params, path, opener);
 	auto http_state = HTTPState::TryGetState(opener).get();
 
@@ -267,21 +248,21 @@ vector<OpenFileInfo> HuggingFaceFileSystem::Glob(const string &path, FileOpener
 	return result;
 }
 
-unique_ptr<ResponseWrapper> HuggingFaceFileSystem::HeadRequest(FileHandle &handle, string hf_url,
-                                                               HeaderMap header_map) {
+unique_ptr<HTTPResponse> HuggingFaceFileSystem::HeadRequest(FileHandle &handle, string hf_url,
+                                                               HTTPHeaders header_map) {
 	auto &hf_handle = handle.Cast<HFFileHandle>();
 	auto http_url = HuggingFaceFileSystem::GetFileUrl(hf_handle.parsed_url);
 	return HTTPFileSystem::HeadRequest(handle, http_url, header_map);
 }
 
-unique_ptr<ResponseWrapper> HuggingFaceFileSystem::GetRequest(FileHandle &handle, string s3_url, HeaderMap header_map) {
+unique_ptr<HTTPResponse> HuggingFaceFileSystem::GetRequest(FileHandle &handle, string s3_url, HTTPHeaders header_map) {
 	auto &hf_handle = handle.Cast<HFFileHandle>();
 	auto http_url = HuggingFaceFileSystem::GetFileUrl(hf_handle.parsed_url);
 	return HTTPFileSystem::GetRequest(handle, http_url, header_map);
 }
 
-unique_ptr<ResponseWrapper> HuggingFaceFileSystem::GetRangeRequest(FileHandle &handle, string s3_url,
-                                                                   HeaderMap header_map, idx_t file_offset,
+unique_ptr<HTTPResponse> HuggingFaceFileSystem::GetRangeRequest(FileHandle &handle, string s3_url,
+                                                                   HTTPHeaders header_map, idx_t file_offset,
                                                                    char *buffer_out, idx_t buffer_out_len) {
 	auto &hf_handle = handle.Cast<HFFileHandle>();
 	auto http_url = HuggingFaceFileSystem::GetFileUrl(hf_handle.parsed_url);
@@ -297,13 +278,13 @@ unique_ptr<HTTPFileHandle> HuggingFaceFileSystem::CreateHandle(const OpenFileInf
 	FileOpenerInfo info;
 	info.file_path = file.path;
 
-	auto params = HTTPParams::ReadFrom(opener, info);
+	auto params = HTTPFSParams::ReadFrom(opener, info);
 	SetParams(params, file.path, opener);
 
 	return duckdb::make_uniq<HFFileHandle>(*this, std::move(parsed_url), file, flags, params);
 }
 
-void HuggingFaceFileSystem::SetParams(HTTPParams &params, const string &path, optional_ptr<FileOpener> opener) {
+void HuggingFaceFileSystem::SetParams(HTTPFSParams &params, const string &path, optional_ptr<FileOpener> opener) {
 	auto secret_manager = FileOpener::TryGetSecretManager(opener);
 	auto transaction = FileOpener::TryGetCatalogTransaction(opener);
 	if (secret_manager && transaction) {
diff --git a/extension/httpfs/httpfs.cpp b/extension/httpfs/httpfs.cpp
index 13ac1d2..7fa1034 100644
--- a/extension/httpfs/httpfs.cpp
+++ b/extension/httpfs/httpfs.cpp
@@ -19,27 +19,22 @@
 #include <string>
 #include <thread>
 
-#define CPPHTTPLIB_OPENSSL_SUPPORT
-#include "httplib.hpp"
-
 namespace duckdb {
 
-duckdb::unique_ptr<duckdb_httplib_openssl::Headers> HTTPFileSystem::InitializeHeaders(HeaderMap &header_map,
-                                                                                      const HTTPParams &http_params) {
-	auto headers = make_uniq<duckdb_httplib_openssl::Headers>();
-	for (auto &entry : header_map) {
-		headers->insert(entry);
-	}
-
-	for (auto &entry : http_params.extra_headers) {
-		headers->insert(entry);
+shared_ptr<HTTPUtil> GetHTTPUtil(optional_ptr<FileOpener> opener) {
+	if (opener) {
+		auto db = opener->TryGetDatabase();
+		if (db) {
+			auto &config = DBConfig::GetConfig(*db);
+			return config.http_util;
+		}
 	}
-
-	return headers;
+	return make_shared_ptr<HTTPFSUtil>();
 }
 
-HTTPParams HTTPParams::ReadFrom(optional_ptr<FileOpener> opener, optional_ptr<FileOpenerInfo> info) {
-	auto result = HTTPParams();
+HTTPFSParams HTTPFSParams::ReadFrom(optional_ptr<FileOpener> opener, optional_ptr<FileOpenerInfo> info) {
+	HTTPFSParams result;
+	result.http_util = GetHTTPUtil(opener);
 
 	// No point in continueing without an opener
 	if (!opener) {
@@ -63,8 +58,19 @@ HTTPParams HTTPParams::ReadFrom(optional_ptr<FileOpener> opener, optional_ptr<Fi
 	// HTTP Secret lookups
 	KeyValueSecretReader settings_reader(*opener, info, "http");
 
+	auto client_context = FileOpener::TryGetClientContext(opener);
+	if (client_context) {
+		result.Initialize(*client_context);
+	} else {
+		auto db = FileOpener::TryGetDatabase(opener);
+		if (db) {
+			result.Initialize(*db);
+		}
+	}
+
+
 	string proxy_setting;
-	if (settings_reader.TryGetSecretKeyOrSetting<string>("http_proxy", "http_proxy", proxy_setting) &&
+	if (settings_reader.TryGetSecretKey<string>("http_proxy", proxy_setting) &&
 	    !proxy_setting.empty()) {
 		idx_t port;
 		string host;
@@ -72,9 +78,9 @@ HTTPParams HTTPParams::ReadFrom(optional_ptr<FileOpener> opener, optional_ptr<Fi
 		result.http_proxy = host;
 		result.http_proxy_port = port;
 	}
-	settings_reader.TryGetSecretKeyOrSetting<string>("http_proxy_username", "http_proxy_username",
+	settings_reader.TryGetSecretKey<string>("http_proxy_username",
 	                                                 result.http_proxy_username);
-	settings_reader.TryGetSecretKeyOrSetting<string>("http_proxy_password", "http_proxy_password",
+	settings_reader.TryGetSecretKey<string>("http_proxy_password",
 	                                                 result.http_proxy_password);
 	settings_reader.TryGetSecretKey<string>("bearer_token", result.bearer_token);
 
@@ -91,7 +97,7 @@ HTTPParams HTTPParams::ReadFrom(optional_ptr<FileOpener> opener, optional_ptr<Fi
 	return result;
 }
 
-unique_ptr<duckdb_httplib_openssl::Client> HTTPClientCache::GetClient() {
+unique_ptr<HTTPClient> HTTPClientCache::GetClient() {
 	lock_guard<mutex> lck(lock);
 	if (clients.size() == 0) {
 		return nullptr;
@@ -102,362 +108,154 @@ unique_ptr<duckdb_httplib_openssl::Client> HTTPClientCache::GetClient() {
 	return client;
 }
 
-void HTTPClientCache::StoreClient(unique_ptr<duckdb_httplib_openssl::Client> client) {
+void HTTPClientCache::StoreClient(unique_ptr<HTTPClient> client) {
 	lock_guard<mutex> lck(lock);
 	clients.push_back(std::move(client));
 }
 
-void HTTPFileSystem::ParseUrl(string &url, string &path_out, string &proto_host_port_out) {
-	if (url.rfind("http://", 0) != 0 && url.rfind("https://", 0) != 0) {
-		throw IOException("URL needs to start with http:// or https://");
-	}
-	auto slash_pos = url.find('/', 8);
-	if (slash_pos == string::npos) {
-		throw IOException("URL needs to contain a '/' after the host");
-	}
-	proto_host_port_out = url.substr(0, slash_pos);
-
-	path_out = url.substr(slash_pos);
-
-	if (path_out.empty()) {
-		throw IOException("URL needs to contain a path");
-	}
-}
-
-// Retry the request performed by fun using the exponential backoff strategy defined in params. Before retry, the
-// retry callback is called
-duckdb::unique_ptr<ResponseWrapper>
-HTTPFileSystem::RunRequestWithRetry(const std::function<duckdb_httplib_openssl::Result(void)> &request, string &url,
-                                    string method, const HTTPParams &params,
-                                    const std::function<void(void)> &retry_cb) {
-	idx_t tries = 0;
-	while (true) {
-		std::exception_ptr caught_e = nullptr;
-		duckdb_httplib_openssl::Error err;
-		duckdb_httplib_openssl::Response response;
-		int status;
-
-		try {
-			auto res = request();
-			err = res.error();
-			if (err == duckdb_httplib_openssl::Error::Success) {
-				status = res->status;
-				response = res.value();
-			}
-		} catch (IOException &e) {
-			caught_e = std::current_exception();
-		} catch (HTTPException &e) {
-			caught_e = std::current_exception();
-		}
-
-		// Note: all duckdb_httplib_openssl::Error types will be retried.
-		if (err == duckdb_httplib_openssl::Error::Success) {
-			switch (status) {
-			case 408: // Request Timeout
-			case 418: // Server is pretending to be a teapot
-			case 429: // Rate limiter hit
-			case 500: // Server has error
-			case 503: // Server has error
-			case 504: // Server has error
-				break;
-			default:
-				return make_uniq<ResponseWrapper>(response, url);
-			}
-		}
-
-		tries += 1;
-
-		if (tries <= params.retries) {
-			if (tries > 1) {
-				uint64_t sleep_amount = (uint64_t)((float)params.retry_wait_ms * pow(params.retry_backoff, tries - 2));
-				std::this_thread::sleep_for(std::chrono::milliseconds(sleep_amount));
-			}
-			if (retry_cb) {
-				retry_cb();
-			}
-		} else {
-			if (caught_e) {
-				std::rethrow_exception(caught_e);
-			} else if (err == duckdb_httplib_openssl::Error::Success) {
-				throw HTTPException(response, "Request returned HTTP %d for HTTP %s to '%s'", status, method, url);
-			} else {
-				throw IOException("%s error for HTTP %s to '%s' with status %d", to_string(err), method, url, status);
-			}
-		}
-	}
-}
-
-unique_ptr<ResponseWrapper> HTTPFileSystem::PostRequest(FileHandle &handle, string url, HeaderMap header_map,
-                                                        duckdb::unique_ptr<char[]> &buffer_out, idx_t &buffer_out_len,
+unique_ptr<HTTPResponse> HTTPFileSystem::PostRequest(FileHandle &handle, string url, HTTPHeaders header_map,
+                                                        string &buffer_out,
                                                         char *buffer_in, idx_t buffer_in_len, string params) {
 	auto &hfh = handle.Cast<HTTPFileHandle>();
-	string path, proto_host_port;
-	ParseUrl(url, path, proto_host_port);
-	auto headers = InitializeHeaders(header_map, hfh.http_params);
-	idx_t out_offset = 0;
-
-	std::function<duckdb_httplib_openssl::Result(void)> request([&]() {
-		auto client = GetClient(hfh.http_params, proto_host_port.c_str(), &hfh);
-
-		if (hfh.state) {
-			hfh.state->post_count++;
-			hfh.state->total_bytes_sent += buffer_in_len;
-		}
-
-		// We use a custom Request method here, because there is no Post call with a contentreceiver in httplib
-		duckdb_httplib_openssl::Request req;
-		req.method = "POST";
-		req.path = path;
-		req.headers = *headers;
-		req.headers.emplace("Content-Type", "application/octet-stream");
-		req.content_receiver = [&](const char *data, size_t data_length, uint64_t /*offset*/,
-		                           uint64_t /*total_length*/) {
-			if (hfh.state) {
-				hfh.state->total_bytes_received += data_length;
-			}
-			if (out_offset + data_length > buffer_out_len) {
-				// Buffer too small, increase its size by at least 2x to fit the new value
-				auto new_size = MaxValue<idx_t>(out_offset + data_length, buffer_out_len * 2);
-				auto tmp = duckdb::unique_ptr<char[]> {new char[new_size]};
-				memcpy(tmp.get(), buffer_out.get(), buffer_out_len);
-				buffer_out = std::move(tmp);
-				buffer_out_len = new_size;
-			}
-			memcpy(buffer_out.get() + out_offset, data, data_length);
-			out_offset += data_length;
-			return true;
-		};
-		req.body.assign(buffer_in, buffer_in_len);
-		return client->send(req);
-	});
-
-	return RunRequestWithRetry(request, url, "POST", hfh.http_params);
-}
-
-unique_ptr<duckdb_httplib_openssl::Client> HTTPFileSystem::GetClient(const HTTPParams &http_params,
-                                                                     const char *proto_host_port,
-                                                                     optional_ptr<HTTPFileHandle> hfh) {
-	auto client = make_uniq<duckdb_httplib_openssl::Client>(proto_host_port);
-	client->set_follow_location(true);
-	client->set_keep_alive(http_params.keep_alive);
-	if (!http_params.ca_cert_file.empty()) {
-		client->set_ca_cert_path(http_params.ca_cert_file.c_str());
-	}
-	client->enable_server_certificate_verification(http_params.enable_server_cert_verification);
-	client->set_write_timeout(http_params.timeout, http_params.timeout_usec);
-	client->set_read_timeout(http_params.timeout, http_params.timeout_usec);
-	client->set_connection_timeout(http_params.timeout, http_params.timeout_usec);
-	client->set_decompress(false);
-	if (hfh && hfh->http_logger) {
-		client->set_logger(
-		    hfh->http_logger->GetLogger<duckdb_httplib_openssl::Request, duckdb_httplib_openssl::Response>());
-	}
-	if (!http_params.bearer_token.empty()) {
-		client->set_bearer_token_auth(http_params.bearer_token.c_str());
-	}
-
-	if (!http_params.http_proxy.empty()) {
-		client->set_proxy(http_params.http_proxy, http_params.http_proxy_port);
-
-		if (!http_params.http_proxy_username.empty()) {
-			client->set_proxy_basic_auth(http_params.http_proxy_username, http_params.http_proxy_password);
-		}
-	}
-
-	return client;
+	auto &http_util = *hfh.http_params.http_util;
+	PostRequestInfo post_request(url, header_map, hfh.http_params, const_data_ptr_cast(buffer_in), buffer_in_len);
+	auto result = http_util.Request(post_request);
+	buffer_out = std::move(post_request.buffer_out);
+	return result;
 }
 
-unique_ptr<ResponseWrapper> HTTPFileSystem::PutRequest(FileHandle &handle, string url, HeaderMap header_map,
+unique_ptr<HTTPResponse> HTTPFileSystem::PutRequest(FileHandle &handle, string url, HTTPHeaders header_map,
                                                        char *buffer_in, idx_t buffer_in_len, string params) {
 	auto &hfh = handle.Cast<HTTPFileHandle>();
-	string path, proto_host_port;
-	ParseUrl(url, path, proto_host_port);
-	auto headers = InitializeHeaders(header_map, hfh.http_params);
-
-	std::function<duckdb_httplib_openssl::Result(void)> request([&]() {
-		auto client = GetClient(hfh.http_params, proto_host_port.c_str(), &hfh);
-		if (hfh.state) {
-			hfh.state->put_count++;
-			hfh.state->total_bytes_sent += buffer_in_len;
-		}
-		return client->Put(path.c_str(), *headers, buffer_in, buffer_in_len, "application/octet-stream");
-	});
-
-	return RunRequestWithRetry(request, url, "PUT", hfh.http_params);
+	auto &http_util = *hfh.http_params.http_util;
+	string content_type = "application/octet-stream";
+	PutRequestInfo put_request(url, header_map, hfh.http_params, (const_data_ptr_t) buffer_in, buffer_in_len, content_type);
+	return http_util.Request(put_request);
 }
 
-unique_ptr<ResponseWrapper> HTTPFileSystem::HeadRequest(FileHandle &handle, string url, HeaderMap header_map) {
+unique_ptr<HTTPResponse> HTTPFileSystem::HeadRequest(FileHandle &handle, string url, HTTPHeaders header_map) {
 	auto &hfh = handle.Cast<HTTPFileHandle>();
-	string path, proto_host_port;
-	ParseUrl(url, path, proto_host_port);
-	auto headers = InitializeHeaders(header_map, hfh.http_params);
-	auto http_client = hfh.GetClient(nullptr);
-
-	std::function<duckdb_httplib_openssl::Result(void)> request([&]() {
-		if (hfh.state) {
-			hfh.state->head_count++;
-		}
-		return http_client->Head(path.c_str(), *headers);
-	});
+	auto &http_util = *hfh.http_params.http_util;
+	auto http_client = hfh.GetClient();
 
-	// Refresh the client on retries
-	std::function<void(void)> on_retry(
-	    [&]() { http_client = GetClient(hfh.http_params, proto_host_port.c_str(), &hfh); });
+	HeadRequestInfo head_request(url, header_map, hfh.http_params);
+	auto response = http_util.Request(head_request, http_client);
 
-	auto response = RunRequestWithRetry(request, url, "HEAD", hfh.http_params, on_retry);
 	hfh.StoreClient(std::move(http_client));
 	return response;
 }
-unique_ptr<ResponseWrapper> HTTPFileSystem::DeleteRequest(FileHandle &handle, string url, HeaderMap header_map) {
-	auto &hfh = handle.Cast<HTTPFileHandle>();
-	string path, proto_host_port;
-	ParseUrl(url, path, proto_host_port);
-	auto headers = InitializeHeaders(header_map, hfh.http_params);
-	auto http_client = hfh.GetClient(nullptr);
-
-	std::function<duckdb_httplib_openssl::Result(void)> request([&]() {
-		if (hfh.state) {
-			hfh.state->delete_count++;
-		}
-		return http_client->Delete(path.c_str(), *headers);
-	});
 
-	// Refresh the client on retries
-	std::function<void(void)> on_retry(
-		[&]() { http_client = GetClient(hfh.http_params, proto_host_port.c_str(), &hfh); });
+unique_ptr<HTTPResponse> HTTPFileSystem::DeleteRequest(FileHandle &handle, string url, HTTPHeaders header_map) {
+	auto &hfh = handle.Cast<HTTPFileHandle>();
+	auto &http_util = *hfh.http_params.http_util;
+	auto http_client = hfh.GetClient();
+	DeleteRequestInfo delete_request(url, header_map, hfh.http_params);
+	auto response = http_util.Request(delete_request, http_client);
 
-	auto response = RunRequestWithRetry(request, url, "DELETE", hfh.http_params, on_retry);
 	hfh.StoreClient(std::move(http_client));
 	return response;
 }
 
-unique_ptr<ResponseWrapper> HTTPFileSystem::GetRequest(FileHandle &handle, string url, HeaderMap header_map) {
+unique_ptr<HTTPResponse> HTTPFileSystem::GetRequest(FileHandle &handle, string url, HTTPHeaders header_map) {
 	auto &hfh = handle.Cast<HTTPFileHandle>();
-	string path, proto_host_port;
-	ParseUrl(url, path, proto_host_port);
-	auto headers = InitializeHeaders(header_map, hfh.http_params);
+	auto &http_util = *hfh.http_params.http_util;
 
 	D_ASSERT(hfh.cached_file_handle);
 
-	auto http_client = hfh.GetClient(nullptr);
-
-	std::function<duckdb_httplib_openssl::Result(void)> request([&]() {
-		D_ASSERT(hfh.state);
-		hfh.state->get_count++;
-		return http_client->Get(
-		    path.c_str(), *headers,
-		    [&](const duckdb_httplib_openssl::Response &response) {
-			    if (response.status >= 400) {
-				    string error = "HTTP GET error on '" + url + "' (HTTP " + to_string(response.status) + ")";
-				    if (response.status == 416) {
-					    error += " This could mean the file was changed. Try disabling the duckdb http metadata cache "
-					             "if enabled, and confirm the server supports range requests.";
-				    }
-				    throw IOException(error);
-			    }
-			    return true;
-		    },
-		    [&](const char *data, size_t data_length) {
-			    D_ASSERT(hfh.state);
-			    if (hfh.state) {
-				    hfh.state->total_bytes_received += data_length;
-			    }
-			    if (!hfh.cached_file_handle->GetCapacity()) {
-				    hfh.cached_file_handle->AllocateBuffer(data_length);
-				    hfh.length = data_length;
-				    hfh.cached_file_handle->Write(data, data_length);
-			    } else {
-				    auto new_capacity = hfh.cached_file_handle->GetCapacity();
-				    while (new_capacity < hfh.length + data_length) {
-					    new_capacity *= 2;
-				    }
-				    // Grow buffer when running out of space
-				    if (new_capacity != hfh.cached_file_handle->GetCapacity()) {
-					    hfh.cached_file_handle->GrowBuffer(new_capacity, hfh.length);
-				    }
-				    // We can just copy stuff
-				    hfh.cached_file_handle->Write(data, data_length, hfh.length);
-				    hfh.length += data_length;
-			    }
-			    return true;
-		    });
-	});
-
-	std::function<void(void)> on_retry(
-	    [&]() { http_client = GetClient(hfh.http_params, proto_host_port.c_str(), &hfh); });
-
-	auto response = RunRequestWithRetry(request, url, "GET", hfh.http_params, on_retry);
+	auto http_client = hfh.GetClient();
+	GetRequestInfo get_request(url, header_map, hfh.http_params,
+		[&](const HTTPResponse &response) {
+			if (static_cast<int>(response.status) >= 400) {
+				string error = "HTTP GET error on '" + url + "' (HTTP " + to_string(static_cast<int>(response.status)) + ")";
+				if (response.status == HTTPStatusCode::RangeNotSatisfiable_416) {
+					error += " This could mean the file was changed. Try disabling the duckdb http metadata cache "
+					         "if enabled, and confirm the server supports range requests.";
+				}
+				throw IOException(error);
+			}
+			return true;
+		},
+		[&](const_data_ptr_t data, idx_t data_length) {
+			if (!hfh.cached_file_handle->GetCapacity()) {
+				hfh.cached_file_handle->AllocateBuffer(data_length);
+				hfh.length = data_length;
+				hfh.cached_file_handle->Write(const_char_ptr_cast(data), data_length);
+			} else {
+				auto new_capacity = hfh.cached_file_handle->GetCapacity();
+				while (new_capacity < hfh.length + data_length) {
+					new_capacity *= 2;
+				}
+				// Grow buffer when running out of space
+				if (new_capacity != hfh.cached_file_handle->GetCapacity()) {
+					hfh.cached_file_handle->GrowBuffer(new_capacity, hfh.length);
+				}
+				// We can just copy stuff
+				hfh.cached_file_handle->Write(const_char_ptr_cast(data), data_length, hfh.length);
+				hfh.length += data_length;
+			}
+			return true;
+		});
+
+	auto response = http_util.Request(get_request, http_client);
+
 	hfh.StoreClient(std::move(http_client));
 	return response;
 }
 
-unique_ptr<ResponseWrapper> HTTPFileSystem::GetRangeRequest(FileHandle &handle, string url, HeaderMap header_map,
+unique_ptr<HTTPResponse> HTTPFileSystem::GetRangeRequest(FileHandle &handle, string url, HTTPHeaders header_map,
                                                             idx_t file_offset, char *buffer_out, idx_t buffer_out_len) {
 	auto &hfh = handle.Cast<HTTPFileHandle>();
-	string path, proto_host_port;
-	ParseUrl(url, path, proto_host_port);
-	auto headers = InitializeHeaders(header_map, hfh.http_params);
+	auto &http_util = *hfh.http_params.http_util;
 
 	// send the Range header to read only subset of file
 	string range_expr = "bytes=" + to_string(file_offset) + "-" + to_string(file_offset + buffer_out_len - 1);
-	headers->insert(pair<string, string>("Range", range_expr));
+	header_map.Insert("Range", range_expr);
 
-	auto http_client = hfh.GetClient(nullptr);
+	auto http_client = hfh.GetClient();
 
 	idx_t out_offset = 0;
 
-	std::function<duckdb_httplib_openssl::Result(void)> request([&]() {
-		if (hfh.state) {
-			hfh.state->get_count++;
-		}
-		return http_client->Get(
-		    path.c_str(), *headers,
-		    [&](const duckdb_httplib_openssl::Response &response) {
-			    if (response.status >= 400) {
-				    string error = "HTTP GET error on '" + url + "' (HTTP " + to_string(response.status) + ")";
-				    if (response.status == 416) {
-					    error += " This could mean the file was changed. Try disabling the duckdb http metadata cache "
-					             "if enabled, and confirm the server supports range requests.";
-				    }
-				    throw HTTPException(response, error);
-			    }
-			    if (response.status < 300) { // done redirecting
-				    out_offset = 0;
-				    if (response.has_header("Content-Length")) {
-					    auto content_length = stoll(response.get_header_value("Content-Length", 0));
-					    if ((idx_t)content_length != buffer_out_len) {
-						    throw IOException("HTTP GET error: Content-Length from server mismatches requested "
-						                      "range, server may not support range requests.");
-					    }
-				    }
-			    }
-			    return true;
-		    },
-		    [&](const char *data, size_t data_length) {
-			    if (hfh.state) {
-				    hfh.state->total_bytes_received += data_length;
-			    }
-			    if (buffer_out != nullptr) {
-				    if (data_length + out_offset > buffer_out_len) {
-					    // As of v0.8.2-dev4424 we might end up here when very big files are served from servers
-					    // that returns more data than requested via range header. This is an uncommon but legal
-					    // behaviour, so we have to improve logic elsewhere to properly handle this case.
-
-					    // To avoid corruption of memory, we bail out.
-					    throw IOException("Server sent back more data than expected, `SET force_download=true` might "
-					                      "help in this case");
-				    }
-				    memcpy(buffer_out + out_offset, data, data_length);
-				    out_offset += data_length;
-			    }
-			    return true;
-		    });
-	});
-
-	std::function<void(void)> on_retry(
-	    [&]() { http_client = GetClient(hfh.http_params, proto_host_port.c_str(), &hfh); });
-
-	auto response = RunRequestWithRetry(request, url, "GET Range", hfh.http_params, on_retry);
+	GetRequestInfo get_request(url, header_map, hfh.http_params,
+		[&](const HTTPResponse &response) {
+			if (static_cast<int>(response.status) >= 400) {
+				string error = "HTTP GET error on '" + url + "' (HTTP " + to_string(static_cast<int>(response.status)) + ")";
+				if (response.status == HTTPStatusCode::RangeNotSatisfiable_416) {
+					error += " This could mean the file was changed. Try disabling the duckdb http metadata cache "
+					         "if enabled, and confirm the server supports range requests.";
+				}
+				throw HTTPException(response, error);
+			}
+			if (static_cast<int>(response.status) < 300) { // done redirecting
+				out_offset = 0;
+				if (response.HasHeader("Content-Length")) {
+					auto content_length = stoll(response.GetHeaderValue("Content-Length"));
+					if ((idx_t)content_length != buffer_out_len) {
+						throw IOException("HTTP GET error: Content-Length from server mismatches requested "
+						                  "range, server may not support range requests.");
+					}
+				}
+			}
+			return true;
+		},
+		[&](const_data_ptr_t data, idx_t data_length) {
+			if (buffer_out != nullptr) {
+				if (data_length + out_offset > buffer_out_len) {
+					// As of v0.8.2-dev4424 we might end up here when very big files are served from servers
+					// that returns more data than requested via range header. This is an uncommon but legal
+					// behaviour, so we have to improve logic elsewhere to properly handle this case.
+
+					// To avoid corruption of memory, we bail out.
+					throw IOException("Server sent back more data than expected, `SET force_download=true` might "
+					                  "help in this case");
+				}
+				memcpy(buffer_out + out_offset, data, data_length);
+				out_offset += data_length;
+			}
+			return true;
+		});
+
+	auto response = http_util.Request(get_request, http_client);
+
 	hfh.StoreClient(std::move(http_client));
 	return response;
 }
@@ -475,8 +273,8 @@ void TimestampToTimeT(timestamp_t timestamp, time_t &result) {
 	result = mktime(&tm);
 }
 
-HTTPFileHandle::HTTPFileHandle(FileSystem &fs, const OpenFileInfo &file, FileOpenFlags flags, const HTTPParams &http_params)
-    : FileHandle(fs, file.path, flags), http_params(http_params), flags(flags), length(0), buffer_available(0),
+HTTPFileHandle::HTTPFileHandle(FileSystem &fs, const OpenFileInfo &file, FileOpenFlags flags, HTTPFSParams http_params_p)
+    : FileHandle(fs, file.path, flags), http_params(std::move(http_params_p)), flags(flags), length(0), buffer_available(0),
       buffer_idx(0), file_offset(0), buffer_start(0), buffer_end(0) {
 	// check if the handle has extended properties that can be set directly in the handle
 	// if we have these properties we don't need to do a head request to obtain them later
@@ -501,14 +299,13 @@ HTTPFileHandle::HTTPFileHandle(FileSystem &fs, const OpenFileInfo &file, FileOpe
 		}
 	}
 }
-
 unique_ptr<HTTPFileHandle> HTTPFileSystem::CreateHandle(const OpenFileInfo &file, FileOpenFlags flags,
                                                         optional_ptr<FileOpener> opener) {
 	D_ASSERT(flags.Compression() == FileCompressionType::UNCOMPRESSED);
 
 	FileOpenerInfo info;
 	info.file_path = file.path;
-	auto params = HTTPParams::ReadFrom(opener, info);
+	auto params = HTTPFSParams::ReadFrom(opener, info);
 
 	auto secret_manager = FileOpener::TryGetSecretManager(opener);
 	auto transaction = FileOpener::TryGetCatalogTransaction(opener);
@@ -520,13 +317,7 @@ unique_ptr<HTTPFileHandle> HTTPFileSystem::CreateHandle(const OpenFileInfo &file
 			params.bearer_token = kv_secret.TryGetValue("token", true).ToString();
 		}
 	}
-
-	auto result = duckdb::make_uniq<HTTPFileHandle>(*this, file, flags, params);
-	auto client_context = FileOpener::TryGetClientContext(opener);
-	if (client_context && ClientConfig::GetConfig(*client_context).enable_http_logging) {
-		result->http_logger = client_context->client_data->http_logger.get();
-	}
-	return result;
+	return duckdb::make_uniq<HTTPFileHandle>(*this, file, flags, params);
 }
 
 unique_ptr<FileHandle> HTTPFileSystem::OpenFileExtended(const OpenFileInfo &file, FileOpenFlags flags,
@@ -553,7 +344,7 @@ unique_ptr<FileHandle> HTTPFileSystem::OpenFileExtended(const OpenFileInfo &file
 void HTTPFileSystem::Read(FileHandle &handle, void *buffer, int64_t nr_bytes, idx_t location) {
 	auto &hfh = handle.Cast<HTTPFileHandle>();
 
-	D_ASSERT(hfh.state);
+	D_ASSERT(hfh.http_params.state);
 	if (hfh.cached_file_handle) {
 		if (!hfh.cached_file_handle->Initialized()) {
 			throw InternalException("Cached file not initialized properly");
@@ -721,15 +512,15 @@ static optional_ptr<HTTPMetadataCache> TryGetMetadataCache(optional_ptr<FileOpen
 
 void HTTPFileHandle::FullDownload(HTTPFileSystem &hfs, bool &should_write_cache) {
 	// We are going to download the file at full, we don't need to do no head request.
-	const auto &cache_entry = state->GetCachedFile(path);
+	const auto &cache_entry = http_params.state->GetCachedFile(path);
 	cached_file_handle = cache_entry->GetHandle();
 	if (!cached_file_handle->Initialized()) {
 		// Try to fully download the file first
 		const auto full_download_result = hfs.GetRequest(*this, path, {});
-		if (full_download_result->code != 200) {
+		if (full_download_result->status != HTTPStatusCode::OK_200) {
 			throw HTTPException(*full_download_result, "Full download failed to to URL \"%s\": %s (%s)",
-			                    full_download_result->http_url, to_string(full_download_result->code),
-			                    full_download_result->error);
+			                    full_download_result->url, static_cast<int>(full_download_result->status),
+			                    full_download_result->GetError());
 		}
 		// Mark the file as initialized, set its final length, and unlock it to allowing parallel reads
 		cached_file_handle->SetInitialized(length);
@@ -766,8 +557,8 @@ void HTTPFileHandle::LoadFileInfo() {
 	auto res = hfs.HeadRequest(*this, path, {});
 	string range_length;
 
-	if (res->code != 200) {
-		if (flags.OpenForWriting() && res->code == 404) {
+	if (res->status != HTTPStatusCode::OK_200) {
+		if (flags.OpenForWriting() && res->status == HTTPStatusCode::NotFound_404) {
 			if (!flags.CreateFileIfNotExists() && !flags.OverwriteExistingFile()) {
 				throw IOException("Unable to open URL \"" + path +
 				                  "\" for writing: file does not exist and CREATE flag is not set");
@@ -776,92 +567,93 @@ void HTTPFileHandle::LoadFileInfo() {
 			return;
 		} else {
 			// HEAD request fail, use Range request for another try (read only one byte)
-			if (flags.OpenForReading() && res->code != 404) {
+			if (flags.OpenForReading() && res->status != HTTPStatusCode::NotFound_404) {
 				auto range_res = hfs.GetRangeRequest(*this, path, {}, 0, nullptr, 2);
-				if (range_res->code != 206 && range_res->code != 202 && range_res->code != 200) {
-					throw IOException("Unable to connect to URL \"%s\": %d (%s).", path, res->code, res->error);
+				if (range_res->status != HTTPStatusCode::PartialContent_206 && range_res->status != HTTPStatusCode::Accepted_202 && range_res->status != HTTPStatusCode::OK_200) {
+					throw IOException("Unable to connect to URL \"%s\": %d (%s).", path, static_cast<int>(res->status), res->GetError());
 				}
-				auto range_find = range_res->headers["Content-Range"].find("/");
-				if (!(range_find == std::string::npos || range_res->headers["Content-Range"].size() < range_find + 1)) {
-					range_length = range_res->headers["Content-Range"].substr(range_find + 1);
+				string content_range;
+				if (range_res->headers.HasHeader("Content-Range")) {
+					content_range = range_res->headers.GetHeaderValue("Content-Range");
+				}
+				auto range_find = content_range.find("/");
+				if (!(range_find == std::string::npos || content_range.size() < range_find + 1)) {
+					range_length = content_range.substr(range_find + 1);
 					if (range_length != "*") {
 						res = std::move(range_res);
 					}
 				}
 			} else {
 				// It failed again
-				throw HTTPException(*res, "Unable to connect to URL \"%s\": %s (%s).", res->http_url,
-				                    to_string(res->code), res->error);
+				throw HTTPException(*res, "Unable to connect to URL \"%s\": %d (%s).", res->url,
+				                    static_cast<int>(res->status), res->GetError());
 			}
 		}
 	}
-	if (!res->headers["Last-Modified"].empty()) {
-		HTTPFileSystem::TryParseLastModifiedTime(res->headers["Last-Modified"], last_modified);
+	if (res->headers.HasHeader("Last-Modified")) {
+		HTTPFileSystem::TryParseLastModifiedTime(res->headers.GetHeaderValue("Last-Modified"), last_modified);
 	}
-	if (!res->headers["Etag"].empty()) {
-		etag = res->headers["Etag"];
+	if (res->headers.HasHeader("Etag")) {
+		etag = res->headers.GetHeaderValue("Etag");
 	}
 	initialized = true;
 }
 
 void HTTPFileHandle::Initialize(optional_ptr<FileOpener> opener) {
 	auto &hfs = file_system.Cast<HTTPFileSystem>();
-	state = HTTPState::TryGetState(opener);
-	if (!state) {
-		state = make_shared_ptr<HTTPState>();
-	}
-
-	auto client_context = FileOpener::TryGetClientContext(opener);
-	if (client_context && ClientConfig::GetConfig(*client_context).enable_http_logging) {
-		http_logger = client_context->client_data->http_logger.get();
+	http_params.state = HTTPState::TryGetState(opener);
+	if (!http_params.state) {
+		http_params.state = make_shared_ptr<HTTPState>();
 	}
 
 	auto current_cache = TryGetMetadataCache(opener, hfs);
 
-	bool should_write_cache = false;
-	if (http_params.force_download) {
-		FullDownload(hfs, should_write_cache);
-		return;
-	}
-
-	if (current_cache && !flags.OpenForWriting()) {
-		HTTPMetadataCacheEntry value;
-		bool found = current_cache->Find(path, value);
-
-		if (found) {
-			last_modified = value.last_modified;
-			length = value.length;
-			etag = value.etag;
-
-			if (flags.OpenForReading()) {
-				read_buffer = duckdb::unique_ptr<data_t[]>(new data_t[READ_BUFFER_LEN]);
-			}
-			return;
-		}
-
-		should_write_cache = true;
-	}
-
-	// If we're writing to a file, we might as well remove it from the cache
-	if (current_cache && flags.OpenForWriting()) {
-		current_cache->Erase(path);
-	}
-	LoadFileInfo();
+    bool should_write_cache = false;
+	if (flags.OpenForReading()) {
+        if (http_params.force_download) {
+            FullDownload(hfs, should_write_cache);
+            return;
+        }
+
+        if (current_cache) {
+            HTTPMetadataCacheEntry value;
+            bool found = current_cache->Find(path, value);
+
+            if (found) {
+                last_modified = value.last_modified;
+                length = value.length;
+                etag = value.etag;
+
+                if (flags.OpenForReading()) {
+                    read_buffer = duckdb::unique_ptr<data_t[]>(new data_t[READ_BUFFER_LEN]);
+                }
+                return;
+            }
+
+            should_write_cache = true;
+        }
+    }
+    LoadFileInfo();
 
-	// Initialize the read buffer now that we know the file exists
 	if (flags.OpenForReading()) {
-		read_buffer = duckdb::unique_ptr<data_t[]>(new data_t[READ_BUFFER_LEN]);
-	}
+        if (http_params.state && length == 0) {
+            FullDownload(hfs, should_write_cache);
+        }
+        if (should_write_cache) {
+            current_cache->Insert(path, {length, last_modified, etag});
+        }
 
-	if (state && length == 0) {
-		FullDownload(hfs, should_write_cache);
-	}
-	if (should_write_cache) {
-		current_cache->Insert(path, {length, last_modified, etag});
+        // Initialize the read buffer now that we know the file exists
+        read_buffer = duckdb::unique_ptr<data_t[]>(new data_t[READ_BUFFER_LEN]);
 	}
+
+    // If we're writing to a file, we might as well remove it from the cache
+    if (current_cache && flags.OpenForWriting()) {
+        current_cache->Erase(path);
+    }
 }
 
-unique_ptr<duckdb_httplib_openssl::Client> HTTPFileHandle::GetClient(optional_ptr<ClientContext> context) {
+unique_ptr<HTTPClient> HTTPFileHandle::GetClient() {
 	// Try to fetch a cached client
 	auto cached_client = client_cache.GetClient();
 	if (cached_client) {
@@ -869,35 +661,19 @@ unique_ptr<duckdb_httplib_openssl::Client> HTTPFileHandle::GetClient(optional_pt
 	}
 
 	// Create a new client
-	return CreateClient(context);
+	return CreateClient();
 }
 
-unique_ptr<duckdb_httplib_openssl::Client> HTTPFileHandle::CreateClient(optional_ptr<ClientContext> context) {
+unique_ptr<HTTPClient> HTTPFileHandle::CreateClient() {
 	// Create a new client
 	string path_out, proto_host_port;
-	HTTPFileSystem::ParseUrl(path, path_out, proto_host_port);
-	auto http_client = HTTPFileSystem::GetClient(this->http_params, proto_host_port.c_str(), this);
-	if (context && ClientConfig::GetConfig(*context).enable_http_logging) {
-		http_logger = context->client_data->http_logger.get();
-		http_client->set_logger(
-		    http_logger->GetLogger<duckdb_httplib_openssl::Request, duckdb_httplib_openssl::Response>());
-	}
-	return http_client;
+	HTTPUtil::DecomposeURL(path, path_out, proto_host_port);
+	return http_params.http_util->InitializeClient(http_params, proto_host_port);
 }
 
-void HTTPFileHandle::StoreClient(unique_ptr<duckdb_httplib_openssl::Client> client) {
+void HTTPFileHandle::StoreClient(unique_ptr<HTTPClient> client) {
 	client_cache.StoreClient(std::move(client));
 }
 
-ResponseWrapper::ResponseWrapper(duckdb_httplib_openssl::Response &res, string &original_url) {
-	code = res.status;
-	error = res.reason;
-	for (auto &h : res.headers) {
-		headers[h.first] = h.second;
-	}
-	http_url = original_url;
-	body = res.body;
-}
-
 HTTPFileHandle::~HTTPFileHandle() = default;
 } // namespace duckdb
diff --git a/extension/httpfs/httpfs_client.cpp b/extension/httpfs/httpfs_client.cpp
new file mode 100644
index 0000000..26e485b
--- /dev/null
+++ b/extension/httpfs/httpfs_client.cpp
@@ -0,0 +1,171 @@
+#include "httpfs_client.hpp"
+#include "http_state.hpp"
+#include "duckdb/logging/http_logger.hpp"
+
+#define CPPHTTPLIB_OPENSSL_SUPPORT
+#include "httplib.hpp"
+
+namespace duckdb {
+
+class HTTPFSClient : public HTTPClient {
+public:
+	HTTPFSClient(HTTPFSParams &http_params, const string &proto_host_port) {
+		client = make_uniq<duckdb_httplib_openssl::Client>(proto_host_port);
+		client->set_follow_location(true);
+		client->set_keep_alive(http_params.keep_alive);
+		if (!http_params.ca_cert_file.empty()) {
+			client->set_ca_cert_path(http_params.ca_cert_file.c_str());
+		}
+		client->enable_server_certificate_verification(http_params.enable_server_cert_verification);
+		client->set_write_timeout(http_params.timeout, http_params.timeout_usec);
+		client->set_read_timeout(http_params.timeout, http_params.timeout_usec);
+		client->set_connection_timeout(http_params.timeout, http_params.timeout_usec);
+		client->set_decompress(false);
+		if (http_params.logger) {
+			SetLogger(*http_params.logger);
+		}
+		if (!http_params.bearer_token.empty()) {
+			client->set_bearer_token_auth(http_params.bearer_token.c_str());
+		}
+
+		if (!http_params.http_proxy.empty()) {
+			client->set_proxy(http_params.http_proxy, http_params.http_proxy_port);
+
+			if (!http_params.http_proxy_username.empty()) {
+				client->set_proxy_basic_auth(http_params.http_proxy_username, http_params.http_proxy_password);
+			}
+		}
+		state = http_params.state;
+	}
+
+	void SetLogger(HTTPLogger &logger) {
+		client->set_logger(
+			logger.GetLogger<duckdb_httplib_openssl::Request, duckdb_httplib_openssl::Response>());
+	}
+	unique_ptr<HTTPResponse> Get(GetRequestInfo &info) override {
+		if (state) {
+			state->get_count++;
+		}
+		auto headers = TransformHeaders(info.headers, info.params);
+		if (!info.response_handler && !info.content_handler) {
+			return TransformResult(client->Get(info.path, headers));
+		} else {
+			return TransformResult(client->Get(info.path.c_str(), headers,
+				[&](const duckdb_httplib_openssl::Response &response) {
+					auto http_response = TransformResponse(response);
+					return info.response_handler(*http_response);
+				},
+				[&](const char *data, size_t data_length) {
+					if (state) {
+						state->total_bytes_received += data_length;
+					}
+					return info.content_handler(const_data_ptr_cast(data), data_length);
+				}));
+		}
+	}
+	unique_ptr<HTTPResponse> Put(PutRequestInfo &info) override {
+        if (state) {
+            state->put_count++;
+            state->total_bytes_sent += info.buffer_in_len;
+        }
+        auto headers = TransformHeaders(info.headers, info.params);
+        return TransformResult(client->Put(info.path, headers, const_char_ptr_cast(info.buffer_in), info.buffer_in_len, info.content_type));
+	}
+
+	unique_ptr<HTTPResponse> Head(HeadRequestInfo &info) override {
+        if (state) {
+            state->head_count++;
+        }
+        auto headers = TransformHeaders(info.headers, info.params);
+        return TransformResult(client->Head(info.path, headers));
+	}
+
+	unique_ptr<HTTPResponse> Delete(DeleteRequestInfo &info) override {
+        if (state) {
+            state->delete_count++;
+        }
+        auto headers = TransformHeaders(info.headers, info.params);
+        return TransformResult(client->Delete(info.path, headers));
+	}
+
+	unique_ptr<HTTPResponse> Post(PostRequestInfo &info) override {
+        if (state) {
+            state->post_count++;
+            state->total_bytes_sent += info.buffer_in_len;
+        }
+        // We use a custom Request method here, because there is no Post call with a contentreceiver in httplib
+        duckdb_httplib_openssl::Request req;
+        req.method = "POST";
+        req.path = info.path;
+        req.headers = TransformHeaders(info.headers, info.params);
+        req.headers.emplace("Content-Type", "application/octet-stream");
+        req.content_receiver = [&](const char *data, size_t data_length, uint64_t /*offset*/,
+                                   uint64_t /*total_length*/) {
+            if (state) {
+                state->total_bytes_received += data_length;
+            }
+            info.buffer_out += string(data, data_length);
+            return true;
+        };
+        req.body.assign(const_char_ptr_cast(info.buffer_in), info.buffer_in_len);
+        return TransformResult(client->send(req));
+	}
+
+private:
+    duckdb_httplib_openssl::Headers TransformHeaders(const HTTPHeaders &header_map, const HTTPParams &params) {
+    	duckdb_httplib_openssl::Headers headers;
+        for(auto &entry : header_map) {
+            headers.insert(entry);
+        }
+        for (auto &entry : params.extra_headers) {
+            headers.insert(entry);
+        }
+        return headers;
+    }
+
+    unique_ptr<HTTPResponse> TransformResponse(const duckdb_httplib_openssl::Response &response) {
+        auto status_code = HTTPUtil::ToStatusCode(response.status);
+        auto result = make_uniq<HTTPResponse>(status_code);
+        result->body = response.body;
+        result->reason = response.reason;
+        for (auto &entry : response.headers) {
+            result->headers.Insert(entry.first, entry.second);
+        }
+        return result;
+    }
+
+    unique_ptr<HTTPResponse> TransformResult(duckdb_httplib_openssl::Result &&res) {
+        if (res.error() == duckdb_httplib_openssl::Error::Success) {
+            auto &response = res.value();
+            return TransformResponse(response);
+        } else {
+            auto result = make_uniq<HTTPResponse>(HTTPStatusCode::INVALID);
+            result->request_error = to_string(res.error());
+            return result;
+        }
+    }
+
+private:
+	unique_ptr<duckdb_httplib_openssl::Client> client;
+	optional_ptr<HTTPState> state;
+};
+
+
+unique_ptr<HTTPClient> HTTPFSUtil::InitializeClient(HTTPParams &http_params,
+										const string &proto_host_port) {
+	auto client = make_uniq<HTTPFSClient>(http_params.Cast<HTTPFSParams>(), proto_host_port);
+	return std::move(client);
+}
+
+unordered_map<string, string> HTTPFSUtil::ParseGetParameters(const string &text) {
+	duckdb_httplib_openssl::Params query_params;
+	duckdb_httplib_openssl::detail::parse_query_text(text, query_params);
+
+	unordered_map<string, string> result;
+	for(auto &entry : query_params) {
+		result.emplace(std::move(entry.first), std::move(entry.second));
+	}
+	return result;
+}
+
+}
diff --git a/extension/httpfs/httpfs_config.py b/extension/httpfs/httpfs_config.py
index 99119a2..a9949cb 100644
--- a/extension/httpfs/httpfs_config.py
+++ b/extension/httpfs/httpfs_config.py
@@ -17,6 +17,7 @@ source_files = [
             'http_state.cpp',
             'httpfs.cpp',
             'httpfs_extension.cpp',
+            'httpfs_client.cpp',
             's3fs.cpp',
         ]
     ]
diff --git a/extension/httpfs/httpfs_extension.cpp b/extension/httpfs/httpfs_extension.cpp
index 0ad8eff..a309768 100644
--- a/extension/httpfs/httpfs_extension.cpp
+++ b/extension/httpfs/httpfs_extension.cpp
@@ -11,7 +11,6 @@
 namespace duckdb {
 
 static void LoadInternal(DatabaseInstance &instance) {
-	S3FileSystem::Verify(); // run some tests to see if all the hashes work out
 	auto &fs = instance.GetFileSystem();
 
 	fs.RegisterSubSystem(make_uniq<HTTPFileSystem>());
@@ -62,6 +61,7 @@ static void LoadInternal(DatabaseInstance &instance) {
 	// HuggingFace options
 	config.AddExtensionOption("hf_max_per_page", "Debug option to limit number of items returned in list requests",
 	                          LogicalType::UBIGINT, Value::UBIGINT(0));
+	config.http_util = make_shared_ptr<HTTPFSUtil>();
 
 	auto provider = make_uniq<AWSEnvironmentCredentialsProvider>(config);
 	provider->SetAll();
@@ -70,7 +70,7 @@ static void LoadInternal(DatabaseInstance &instance) {
 	CreateBearerTokenFunctions::Register(instance);
 
 	// set pointer to OpenSSL encryption state
-	config.encryption_util = make_shared_ptr<AESGCMStateSSLFactory>();
+	config.encryption_util = make_shared_ptr<AESStateSSLFactory>();
 }
 void HttpfsExtension::Load(DuckDB &db) {
 	LoadInternal(*db.instance);
diff --git a/extension/httpfs/include/crypto.hpp b/extension/httpfs/include/crypto.hpp
index ff37f23..d81dd2d 100644
--- a/extension/httpfs/include/crypto.hpp
+++ b/extension/httpfs/include/crypto.hpp
@@ -7,6 +7,7 @@
 #include <string>
 
 typedef struct evp_cipher_ctx_st EVP_CIPHER_CTX;
+typedef struct evp_cipher_st EVP_CIPHER;
 
 namespace duckdb {
 
@@ -21,40 +22,42 @@ void hmac256(std::string message, hash_bytes secret, hash_bytes &out);
 
 void hex256(hash_bytes &in, hash_str &out);
 
-class DUCKDB_EXTENSION_API AESGCMStateSSL : public duckdb::EncryptionState {
+class DUCKDB_EXTENSION_API AESStateSSL : public duckdb::EncryptionState {
 
 public:
-	explicit AESGCMStateSSL();
-	~AESGCMStateSSL() override;
+	explicit AESStateSSL(const std::string *key = nullptr);
+	~AESStateSSL() override;
 
 public:
-	bool IsOpenSSL() override;
 	void InitializeEncryption(const_data_ptr_t iv, idx_t iv_len, const std::string *key) override;
 	void InitializeDecryption(const_data_ptr_t iv, idx_t iv_len, const std::string *key) override;
 	size_t Process(const_data_ptr_t in, idx_t in_len, data_ptr_t out, idx_t out_len) override;
 	size_t Finalize(data_ptr_t out, idx_t out_len, data_ptr_t tag, idx_t tag_len) override;
 	void GenerateRandomData(data_ptr_t data, idx_t len) override;
 
+        const EVP_CIPHER *GetCipher(const string &key);
+        size_t FinalizeGCM(data_ptr_t out, idx_t out_len, data_ptr_t tag, idx_t tag_len);
+
 private:
-	bool ssl = true;
-	EVP_CIPHER_CTX *gcm_context;
+	EVP_CIPHER_CTX *context;
 	Mode mode;
+	Cipher cipher = GCM;
 };
 
 } // namespace duckdb
 
 extern "C" {
 
-class DUCKDB_EXTENSION_API AESGCMStateSSLFactory : public duckdb::EncryptionUtil {
+class DUCKDB_EXTENSION_API AESStateSSLFactory : public duckdb::EncryptionUtil {
 public:
-	explicit AESGCMStateSSLFactory() {
+	explicit AESStateSSLFactory() {
 	}
 
-	duckdb::shared_ptr<duckdb::EncryptionState> CreateEncryptionState() const override {
-		return duckdb::make_shared_ptr<duckdb::AESGCMStateSSL>();
+	duckdb::shared_ptr<duckdb::EncryptionState> CreateEncryptionState(const std::string *key = nullptr) const override {
+		return duckdb::make_shared_ptr<duckdb::AESStateSSL>();
 	}
 
-	~AESGCMStateSSLFactory() override {
+	~AESStateSSLFactory() override {
 	}
 };
 }
diff --git a/extension/httpfs/include/hffs.hpp b/extension/httpfs/include/hffs.hpp
index be9fb42..5baa6c5 100644
--- a/extension/httpfs/include/hffs.hpp
+++ b/extension/httpfs/include/hffs.hpp
@@ -24,9 +24,9 @@ public:
 
 	vector<OpenFileInfo> Glob(const string &path, FileOpener *opener = nullptr) override;
 
-	duckdb::unique_ptr<ResponseWrapper> HeadRequest(FileHandle &handle, string hf_url, HeaderMap header_map) override;
-	duckdb::unique_ptr<ResponseWrapper> GetRequest(FileHandle &handle, string hf_url, HeaderMap header_map) override;
-	duckdb::unique_ptr<ResponseWrapper> GetRangeRequest(FileHandle &handle, string hf_url, HeaderMap header_map,
+	duckdb::unique_ptr<HTTPResponse> HeadRequest(FileHandle &handle, string hf_url, HTTPHeaders header_map) override;
+	duckdb::unique_ptr<HTTPResponse> GetRequest(FileHandle &handle, string hf_url, HTTPHeaders header_map) override;
+	duckdb::unique_ptr<HTTPResponse> GetRangeRequest(FileHandle &handle, string hf_url, HTTPHeaders header_map,
 	                                                    idx_t file_offset, char *buffer_out,
 	                                                    idx_t buffer_out_len) override;
 
@@ -42,13 +42,13 @@ public:
 	string GetTreeUrl(const ParsedHFUrl &url, idx_t limit);
 	string GetFileUrl(const ParsedHFUrl &url);
 
-	static void SetParams(HTTPParams &params, const string &path, optional_ptr<FileOpener> opener);
+	static void SetParams(HTTPFSParams &params, const string &path, optional_ptr<FileOpener> opener);
 
 protected:
 	duckdb::unique_ptr<HTTPFileHandle> CreateHandle(const OpenFileInfo &file, FileOpenFlags flags,
 	                                                optional_ptr<FileOpener> opener) override;
 
-	string ListHFRequest(ParsedHFUrl &url, HTTPParams &http_params, string &next_page_url,
+	string ListHFRequest(ParsedHFUrl &url, HTTPFSParams &http_params, string &next_page_url,
 	                     optional_ptr<HTTPState> state);
 };
 
@@ -57,12 +57,12 @@ class HFFileHandle : public HTTPFileHandle {
 
 public:
 	HFFileHandle(FileSystem &fs, ParsedHFUrl hf_url, const OpenFileInfo &file, FileOpenFlags flags,
-	             const HTTPParams &http_params)
+	             const HTTPFSParams &http_params)
 	    : HTTPFileHandle(fs, file, flags, http_params), parsed_url(std::move(hf_url)) {
 	}
 	~HFFileHandle() override;
 
-	unique_ptr<duckdb_httplib_openssl::Client> CreateClient(optional_ptr<ClientContext> client_context) override;
+	unique_ptr<HTTPClient> CreateClient() override;
 
 protected:
 	ParsedHFUrl parsed_url;
diff --git a/extension/httpfs/include/httpfs.hpp b/extension/httpfs/include/httpfs.hpp
index 411de2d..ca1508e 100644
--- a/extension/httpfs/include/httpfs.hpp
+++ b/extension/httpfs/include/httpfs.hpp
@@ -7,78 +7,22 @@
 #include "duckdb/common/unordered_map.hpp"
 #include "duckdb/main/client_data.hpp"
 #include "http_metadata_cache.hpp"
+#include "httpfs_client.hpp"
 
 #include <mutex>
 
-namespace duckdb_httplib_openssl {
-struct Response;
-class Result;
-class Client;
-namespace detail {
-struct ci;
-}
-using Headers = std::multimap<std::string, std::string, duckdb_httplib_openssl::detail::ci>;
-} // namespace duckdb_httplib_openssl
-
 namespace duckdb {
 
-class HTTPLogger;
-
-using HeaderMap = case_insensitive_map_t<string>;
-
-// avoid including httplib in header
-struct ResponseWrapper {
-public:
-	explicit ResponseWrapper(duckdb_httplib_openssl::Response &res, string &original_url);
-	int code;
-	string error;
-	HeaderMap headers;
-	string http_url;
-	string body;
-};
-
-struct HTTPParams {
-
-	static constexpr uint64_t DEFAULT_TIMEOUT_SECONDS = 30; // 30 sec
-	static constexpr uint64_t DEFAULT_RETRIES = 3;
-	static constexpr uint64_t DEFAULT_RETRY_WAIT_MS = 100;
-	static constexpr float DEFAULT_RETRY_BACKOFF = 4;
-	static constexpr bool DEFAULT_FORCE_DOWNLOAD = false;
-	static constexpr bool DEFAULT_KEEP_ALIVE = true;
-	static constexpr bool DEFAULT_ENABLE_SERVER_CERT_VERIFICATION = false;
-	static constexpr uint64_t DEFAULT_HF_MAX_PER_PAGE = 0;
-
-	uint64_t timeout = DEFAULT_TIMEOUT_SECONDS; // seconds component of a timeout
-	uint64_t timeout_usec = 0;                  // usec component of a timeout
-	uint64_t retries = DEFAULT_RETRIES;
-	uint64_t retry_wait_ms = DEFAULT_RETRY_WAIT_MS;
-	float retry_backoff = DEFAULT_RETRY_BACKOFF;
-	bool force_download = DEFAULT_FORCE_DOWNLOAD;
-	bool keep_alive = DEFAULT_KEEP_ALIVE;
-	bool enable_server_cert_verification = DEFAULT_ENABLE_SERVER_CERT_VERIFICATION;
-	idx_t hf_max_per_page = DEFAULT_HF_MAX_PER_PAGE;
-
-	string ca_cert_file;
-	string http_proxy;
-	idx_t http_proxy_port;
-	string http_proxy_username;
-	string http_proxy_password;
-	string bearer_token;
-	unordered_map<string, string> extra_headers;
-
-	static HTTPParams ReadFrom(optional_ptr<FileOpener> opener, optional_ptr<FileOpenerInfo> info);
-};
-
 class HTTPClientCache {
 public:
 	//! Get a client from the client cache
-	unique_ptr<duckdb_httplib_openssl::Client> GetClient();
+	unique_ptr<HTTPClient> GetClient();
 	//! Store a client in the cache for reuse
-	void StoreClient(unique_ptr<duckdb_httplib_openssl::Client> client);
+	void StoreClient(unique_ptr<HTTPClient> client);
 
 protected:
 	//! The cached clients
-	vector<unique_ptr<duckdb_httplib_openssl::Client>> clients;
+	vector<unique_ptr<HTTPClient>> clients;
 	//! Lock to fetch a client
 	mutex lock;
 };
@@ -87,7 +31,7 @@ class HTTPFileSystem;
 
 class HTTPFileHandle : public FileHandle {
 public:
-	HTTPFileHandle(FileSystem &fs, const OpenFileInfo &file, FileOpenFlags flags, const HTTPParams &params);
+	HTTPFileHandle(FileSystem &fs, const OpenFileInfo &file, FileOpenFlags flags, HTTPFSParams params);
 	~HTTPFileHandle() override;
 	// This two-phase construction allows subclasses more flexible setup.
 	virtual void Initialize(optional_ptr<FileOpener> opener);
@@ -95,9 +39,7 @@ public:
 	// We keep an http client stored for connection reuse with keep-alive headers
 	HTTPClientCache client_cache;
 
-	optional_ptr<HTTPLogger> http_logger;
-
-	const HTTPParams http_params;
+	HTTPFSParams http_params;
 
 	// File handle info
 	FileOpenFlags flags;
@@ -123,14 +65,12 @@ public:
 	duckdb::unique_ptr<data_t[]> read_buffer;
 	constexpr static idx_t READ_BUFFER_LEN = 1000000;
 
-	shared_ptr<HTTPState> state;
-
-	void AddHeaders(HeaderMap &map);
+	void AddHeaders(HTTPHeaders &map);
 
 	// Get a Client to run requests over
-	unique_ptr<duckdb_httplib_openssl::Client> GetClient(optional_ptr<ClientContext> client_context);
+	unique_ptr<HTTPClient> GetClient();
 	// Return the client for re-use
-	void StoreClient(unique_ptr<duckdb_httplib_openssl::Client> client);
+	void StoreClient(unique_ptr<HTTPClient> client);
 
 public:
 	void Close() override {
@@ -138,7 +78,7 @@ public:
 
 protected:
 	//! Create a new Client
-	virtual unique_ptr<duckdb_httplib_openssl::Client> CreateClient(optional_ptr<ClientContext> client_context);
+	virtual unique_ptr<HTTPClient> CreateClient();
 	//! Perform a HEAD request to get the file info (if not yet loaded)
 	void LoadFileInfo();
 
@@ -149,34 +89,28 @@ private:
 
 class HTTPFileSystem : public FileSystem {
 public:
-	static duckdb::unique_ptr<duckdb_httplib_openssl::Client>
-	GetClient(const HTTPParams &http_params, const char *proto_host_port, optional_ptr<HTTPFileHandle> hfs);
-	static void ParseUrl(string &url, string &path_out, string &proto_host_port_out);
 	static bool TryParseLastModifiedTime(const string &timestamp, time_t &result);
-	static duckdb::unique_ptr<duckdb_httplib_openssl::Headers> InitializeHeaders(HeaderMap &header_map,
-	                                                                             const HTTPParams &http_params);
 
 	vector<OpenFileInfo> Glob(const string &path, FileOpener *opener = nullptr) override {
 		return {path}; // FIXME
 	}
 
 	// HTTP Requests
-	virtual duckdb::unique_ptr<ResponseWrapper> HeadRequest(FileHandle &handle, string url, HeaderMap header_map);
+	virtual duckdb::unique_ptr<HTTPResponse> HeadRequest(FileHandle &handle, string url, HTTPHeaders header_map);
 	// Get Request with range parameter that GETs exactly buffer_out_len bytes from the url
-	virtual duckdb::unique_ptr<ResponseWrapper> GetRangeRequest(FileHandle &handle, string url, HeaderMap header_map,
+	virtual duckdb::unique_ptr<HTTPResponse> GetRangeRequest(FileHandle &handle, string url, HTTPHeaders header_map,
 	                                                            idx_t file_offset, char *buffer_out,
 	                                                            idx_t buffer_out_len);
 	// Get Request without a range (i.e., downloads full file)
-	virtual duckdb::unique_ptr<ResponseWrapper> GetRequest(FileHandle &handle, string url, HeaderMap header_map);
+	virtual duckdb::unique_ptr<HTTPResponse> GetRequest(FileHandle &handle, string url, HTTPHeaders header_map);
 	// Post Request that can handle variable sized responses without a content-length header (needed for s3 multipart)
-	virtual duckdb::unique_ptr<ResponseWrapper> PostRequest(FileHandle &handle, string url, HeaderMap header_map,
-	                                                        duckdb::unique_ptr<char[]> &buffer_out,
-	                                                        idx_t &buffer_out_len, char *buffer_in, idx_t buffer_in_len,
+	virtual duckdb::unique_ptr<HTTPResponse> PostRequest(FileHandle &handle, string url, HTTPHeaders header_map,
+	                                                        string &result, char *buffer_in, idx_t buffer_in_len,
 	                                                        string params = "");
-	virtual duckdb::unique_ptr<ResponseWrapper> PutRequest(FileHandle &handle, string url, HeaderMap header_map,
+	virtual duckdb::unique_ptr<HTTPResponse> PutRequest(FileHandle &handle, string url, HTTPHeaders header_map,
 	                                                       char *buffer_in, idx_t buffer_in_len, string params = "");
 
-	virtual duckdb::unique_ptr<ResponseWrapper> DeleteRequest(FileHandle &handle, string url, HeaderMap header_map);
+	virtual duckdb::unique_ptr<HTTPResponse> DeleteRequest(FileHandle &handle, string url, HTTPHeaders header_map);
 
 	// FS methods
 	void Read(FileHandle &handle, void *buffer, int64_t nr_bytes, idx_t location) override;
@@ -219,11 +153,6 @@ protected:
 protected:
 	virtual duckdb::unique_ptr<HTTPFileHandle> CreateHandle(const OpenFileInfo &file, FileOpenFlags flags,
 	                                                        optional_ptr<FileOpener> opener);
-
-	static duckdb::unique_ptr<ResponseWrapper>
-	RunRequestWithRetry(const std::function<duckdb_httplib_openssl::Result(void)> &request, string &url, string method,
-	                    const HTTPParams &params, const std::function<void(void)> &retry_cb = {});
-
 private:
 	// Global cache
 	mutex global_cache_lock;
diff --git a/extension/httpfs/include/httpfs_client.hpp b/extension/httpfs/include/httpfs_client.hpp
new file mode 100644
index 0000000..4b0c33e
--- /dev/null
+++ b/extension/httpfs/include/httpfs_client.hpp
@@ -0,0 +1,32 @@
+#include "duckdb/common/http_util.hpp"
+
+namespace duckdb {
+class HTTPLogger;
+class FileOpener;
+struct FileOpenerInfo;
+class HTTPState;
+
+struct HTTPFSParams : public HTTPParams {
+	static constexpr bool DEFAULT_ENABLE_SERVER_CERT_VERIFICATION = false;
+	static constexpr uint64_t DEFAULT_HF_MAX_PER_PAGE = 0;
+	static constexpr bool DEFAULT_FORCE_DOWNLOAD = false;
+
+	bool force_download = DEFAULT_FORCE_DOWNLOAD;
+	bool enable_server_cert_verification = DEFAULT_ENABLE_SERVER_CERT_VERIFICATION;
+	idx_t hf_max_per_page = DEFAULT_HF_MAX_PER_PAGE;
+	string ca_cert_file;
+	string bearer_token;
+	shared_ptr<HTTPUtil> http_util;
+	shared_ptr<HTTPState> state;
+
+	static HTTPFSParams ReadFrom(optional_ptr<FileOpener> opener, optional_ptr<FileOpenerInfo> info);
+};
+
+class HTTPFSUtil : public HTTPUtil {
+public:
+	unique_ptr<HTTPClient> InitializeClient(HTTPParams &http_params, const string &proto_host_port) override;
+
+	static unordered_map<string, string> ParseGetParameters(const string &text);
+};
+
+}
diff --git a/extension/httpfs/include/s3fs.hpp b/extension/httpfs/include/s3fs.hpp
index 229c79e..e389e56 100644
--- a/extension/httpfs/include/s3fs.hpp
+++ b/extension/httpfs/include/s3fs.hpp
@@ -12,9 +12,6 @@
 #include "duckdb/common/case_insensitive_map.hpp"
 #include "httpfs.hpp"
 
-#define CPPHTTPLIB_OPENSSL_SUPPORT
-#include "httplib.hpp"
-
 #include <condition_variable>
 #include <exception>
 #include <iostream>
@@ -111,9 +108,9 @@ class S3FileHandle : public HTTPFileHandle {
 	friend class S3FileSystem;
 
 public:
-	S3FileHandle(FileSystem &fs, const OpenFileInfo &file, FileOpenFlags flags, const HTTPParams &http_params,
+	S3FileHandle(FileSystem &fs, const OpenFileInfo &file, FileOpenFlags flags, HTTPFSParams http_params_p,
 	             const S3AuthParams &auth_params_p, const S3ConfigParams &config_params_p)
-	    : HTTPFileHandle(fs, file, flags, http_params), auth_params(auth_params_p),
+	    : HTTPFileHandle(fs, file, flags, std::move(http_params_p)), auth_params(auth_params_p),
 	      config_params(config_params_p), uploads_in_progress(0), parts_uploaded(0), upload_finalized(false),
 	      uploader_has_error(false), upload_exception(nullptr) {
 		if (flags.OpenForReading() && flags.OpenForWriting()) {
@@ -159,7 +156,7 @@ protected:
 	atomic<bool> uploader_has_error {false};
 	std::exception_ptr upload_exception;
 
-	unique_ptr<duckdb_httplib_openssl::Client> CreateClient(optional_ptr<ClientContext> client_context) override;
+	unique_ptr<HTTPClient> CreateClient() override;
 
 	//! Rethrow IO Exception originating from an upload thread
 	void RethrowIOError() {
@@ -178,21 +175,19 @@ public:
 	string GetName() const override;
 
 public:
-	duckdb::unique_ptr<ResponseWrapper> HeadRequest(FileHandle &handle, string s3_url, HeaderMap header_map) override;
-	duckdb::unique_ptr<ResponseWrapper> GetRequest(FileHandle &handle, string url, HeaderMap header_map) override;
-	duckdb::unique_ptr<ResponseWrapper> GetRangeRequest(FileHandle &handle, string s3_url, HeaderMap header_map,
+	duckdb::unique_ptr<HTTPResponse> HeadRequest(FileHandle &handle, string s3_url, HTTPHeaders header_map) override;
+	duckdb::unique_ptr<HTTPResponse> GetRequest(FileHandle &handle, string url, HTTPHeaders header_map) override;
+	duckdb::unique_ptr<HTTPResponse> GetRangeRequest(FileHandle &handle, string s3_url, HTTPHeaders header_map,
 	                                                    idx_t file_offset, char *buffer_out,
 	                                                    idx_t buffer_out_len) override;
-	duckdb::unique_ptr<ResponseWrapper> PostRequest(FileHandle &handle, string s3_url, HeaderMap header_map,
-	                                                duckdb::unique_ptr<char[]> &buffer_out, idx_t &buffer_out_len,
+	duckdb::unique_ptr<HTTPResponse> PostRequest(FileHandle &handle, string s3_url, HTTPHeaders header_map,
+	                                                string &buffer_out,
 	                                                char *buffer_in, idx_t buffer_in_len,
 	                                                string http_params = "") override;
-	duckdb::unique_ptr<ResponseWrapper> PutRequest(FileHandle &handle, string s3_url, HeaderMap header_map,
+	duckdb::unique_ptr<HTTPResponse> PutRequest(FileHandle &handle, string s3_url, HTTPHeaders header_map,
 	                                               char *buffer_in, idx_t buffer_in_len,
 	                                               string http_params = "") override;
-	duckdb::unique_ptr<ResponseWrapper> DeleteRequest(FileHandle &handle, string s3_url, HeaderMap header_map) override;
-
-	static void Verify();
+	duckdb::unique_ptr<HTTPResponse> DeleteRequest(FileHandle &handle, string s3_url, HTTPHeaders header_map) override;
 
 	bool CanHandleFile(const string &fpath) override;
 	bool OnDiskFile(FileHandle &handle) override {
@@ -237,14 +232,11 @@ protected:
 
 	void FlushBuffer(S3FileHandle &handle, shared_ptr<S3WriteBuffer> write_buffer);
 	string GetPayloadHash(char *buffer, idx_t buffer_len);
-
-	// helper for ReadQueryParams
-	void GetQueryParam(const string &key, string &param, CPPHTTPLIB_NAMESPACE::Params &query_params);
 };
 
 // Helper class to do s3 ListObjectV2 api call https://docs.aws.amazon.com/AmazonS3/latest/API/API_ListObjectsV2.html
 struct AWSListObjectV2 {
-	static string Request(string &path, HTTPParams &http_params, S3AuthParams &s3_auth_params,
+	static string Request(string &path, HTTPFSParams &http_params, S3AuthParams &s3_auth_params,
 	                      string &continuation_token, optional_ptr<HTTPState> state, bool use_delimiter = false);
 	static void ParseFileList(string &aws_response, vector<OpenFileInfo> &result);
 	static vector<string> ParseCommonPrefix(string &aws_response);
diff --git a/extension/httpfs/s3fs.cpp b/extension/httpfs/s3fs.cpp
index 7ec018c..8245318 100644
--- a/extension/httpfs/s3fs.cpp
+++ b/extension/httpfs/s3fs.cpp
@@ -23,11 +23,11 @@
 
 namespace duckdb {
 
-static HeaderMap create_s3_header(string url, string query, string host, string service, string method,
+static HTTPHeaders create_s3_header(string url, string query, string host, string service, string method,
                                   const S3AuthParams &auth_params, string date_now = "", string datetime_now = "",
                                   string payload_hash = "", string content_type = "") {
 
-	HeaderMap res;
+	HTTPHeaders res;
 	res["Host"] = host;
 	// If access key is not set, we don't set the headers at all to allow accessing public files through s3 urls
 	if (auth_params.secret_access_key.empty() && auth_params.access_key_id.empty()) {
@@ -110,14 +110,6 @@ static HeaderMap create_s3_header(string url, string query, string host, string
 	return res;
 }
 
-static duckdb::unique_ptr<duckdb_httplib_openssl::Headers> initialize_http_headers(HeaderMap &header_map) {
-	auto headers = make_uniq<duckdb_httplib_openssl::Headers>();
-	for (auto &entry : header_map) {
-		headers->insert(entry);
-	}
-	return headers;
-}
-
 string S3FileSystem::UrlDecode(string input) {
 	return StringUtil::URLDecode(input, true);
 }
@@ -279,11 +271,11 @@ void S3FileHandle::Close() {
 	}
 }
 
-unique_ptr<duckdb_httplib_openssl::Client> S3FileHandle::CreateClient(optional_ptr<ClientContext> client_context) {
+unique_ptr<HTTPClient> S3FileHandle::CreateClient() {
 	auto parsed_url = S3FileSystem::S3UrlParse(path, this->auth_params);
 
 	string proto_host_port = parsed_url.http_proto + parsed_url.host;
-	return HTTPFileSystem::GetClient(this->http_params, proto_host_port.c_str(), this);
+	return http_params.http_util->InitializeClient(http_params, proto_host_port);
 }
 
 // Opens the multipart upload and returns the ID
@@ -291,20 +283,16 @@ string S3FileSystem::InitializeMultipartUpload(S3FileHandle &file_handle) {
 	auto &s3fs = (S3FileSystem &)file_handle.file_system;
 
 	// AWS response is around 300~ chars in docs so this should be enough to not need a resize
-	idx_t response_buffer_len = 1000;
-	auto response_buffer = duckdb::unique_ptr<char[]> {new char[response_buffer_len]};
-
+	string result;
 	string query_param = "uploads=";
-	auto res = s3fs.PostRequest(file_handle, file_handle.path, {}, response_buffer, response_buffer_len, nullptr, 0,
+	auto res = s3fs.PostRequest(file_handle, file_handle.path, {}, result, nullptr, 0,
 	                            query_param);
 
-	if (res->code != 200) {
-		throw HTTPException(*res, "Unable to connect to URL %s: %s (HTTP code %s)", res->http_url, res->error,
-							to_string(res->code));
+	if (res->status != HTTPStatusCode::OK_200) {
+		throw HTTPException(*res, "Unable to connect to URL %s: %s (HTTP code %d)", res->url, res->GetError(),
+							static_cast<int>(res->status));
 	}
 
-	string result(response_buffer.get(), response_buffer_len);
-
 	auto open_tag_pos = result.find("<UploadId>", 0);
 	auto close_tag_pos = result.find("</UploadId>", open_tag_pos);
 
@@ -333,23 +321,22 @@ void S3FileSystem::UploadBuffer(S3FileHandle &file_handle, shared_ptr<S3WriteBuf
 
 	string query_param = "partNumber=" + to_string(write_buffer->part_no + 1) + "&" +
 	                     "uploadId=" + S3FileSystem::UrlEncode(file_handle.multipart_upload_id, true);
-	unique_ptr<ResponseWrapper> res;
-	case_insensitive_map_t<string>::iterator etag_lookup;
+	unique_ptr<HTTPResponse> res;
+	string etag;
 
 	try {
 		res = s3fs.PutRequest(file_handle, file_handle.path, {}, (char *)write_buffer->Ptr(), write_buffer->idx,
 		                      query_param);
 
-		if (res->code != 200) {
-			throw HTTPException(*res, "Unable to connect to URL %s: %s (HTTP code %s)", res->http_url, res->error,
-			                    to_string(res->code));
+		if (res->status != HTTPStatusCode::OK_200) {
+			throw HTTPException(*res, "Unable to connect to URL %s: %s (HTTP code %d)", res->url, res->GetError(),
+			                    static_cast<int>(res->status));
 		}
 
-		etag_lookup = res->headers.find("ETag");
-		if (etag_lookup == res->headers.end()) {
+		if (!res->headers.HasHeader("ETag")) {
 			throw IOException("Unexpected response when uploading part to S3");
 		}
-
+		etag = res->headers.GetHeaderValue("ETag");
 	} catch (std::exception &ex) {
 		ErrorData error(ex);
 		if (error.Type() != ExceptionType::IO && error.Type() != ExceptionType::HTTP) {
@@ -369,7 +356,7 @@ void S3FileSystem::UploadBuffer(S3FileHandle &file_handle, shared_ptr<S3WriteBuf
 	// Insert etag
 	{
 		unique_lock<mutex> lck(file_handle.part_etags_lock);
-		file_handle.part_etags.insert(std::pair<uint16_t, string>(write_buffer->part_no, etag_lookup->second));
+		file_handle.part_etags.insert(std::pair<uint16_t, string>(write_buffer->part_no, etag));
 	}
 
 	file_handle.parts_uploaded++;
@@ -460,17 +447,14 @@ void S3FileSystem::FinalizeMultipartUpload(S3FileHandle &file_handle) {
 	string body = ss.str();
 
 	// Response is around ~400 in AWS docs so this should be enough to not need a resize
-	idx_t response_buffer_len = 1000;
-	auto response_buffer = duckdb::unique_ptr<char[]> {new char[response_buffer_len]};
+	string result;
 
 	string query_param = "uploadId=" + S3FileSystem::UrlEncode(file_handle.multipart_upload_id, true);
-	auto res = s3fs.PostRequest(file_handle, file_handle.path, {}, response_buffer, response_buffer_len,
+	auto res = s3fs.PostRequest(file_handle, file_handle.path, {}, result,
 	                            (char *)body.c_str(), body.length(), query_param);
-	string result(response_buffer.get(), response_buffer_len);
-
 	auto open_tag_pos = result.find("<CompleteMultipartUploadResult", 0);
 	if (open_tag_pos == string::npos) {
-		throw HTTPException(*res, "Unexpected response during S3 multipart upload finalization: %d\n\n%s", res->code,
+		throw HTTPException(*res, "Unexpected response during S3 multipart upload finalization: %d\n\n%s", static_cast<int>(res->status),
 		                    result);
 	}
 }
@@ -512,7 +496,7 @@ shared_ptr<S3WriteBuffer> S3FileHandle::GetBuffer(uint16_t write_buffer_idx) {
 	return new_write_buffer;
 }
 
-void S3FileSystem::GetQueryParam(const string &key, string &param, duckdb_httplib_openssl::Params &query_params) {
+void GetQueryParam(const string &key, string &param, unordered_map<string, string> &query_params) {
 	auto found_param = query_params.find(key);
 	if (found_param != query_params.end()) {
 		param = found_param->second;
@@ -525,8 +509,7 @@ void S3FileSystem::ReadQueryParams(const string &url_query_param, S3AuthParams &
 		return;
 	}
 
-	duckdb_httplib_openssl::Params query_params;
-	duckdb_httplib_openssl::detail::parse_query_text(url_query_param, query_params);
+	auto query_params = HTTPFSUtil::ParseGetParameters(url_query_param);
 
 	GetQueryParam("s3_region", params.region, query_params);
 	GetQueryParam("s3_access_key_id", params.access_key_id, query_params);
@@ -652,8 +635,8 @@ string ParsedS3Url::GetHTTPUrl(S3AuthParams &auth_params, const string &http_que
 	return full_url;
 }
 
-unique_ptr<ResponseWrapper> S3FileSystem::PostRequest(FileHandle &handle, string url, HeaderMap header_map,
-                                                      duckdb::unique_ptr<char[]> &buffer_out, idx_t &buffer_out_len,
+unique_ptr<HTTPResponse> S3FileSystem::PostRequest(FileHandle &handle, string url, HTTPHeaders header_map,
+                                                      string &result,
                                                       char *buffer_in, idx_t buffer_in_len, string http_params) {
 	auto auth_params = handle.Cast<S3FileHandle>().auth_params;
 	auto parsed_s3_url = S3UrlParse(url, auth_params);
@@ -662,10 +645,10 @@ unique_ptr<ResponseWrapper> S3FileSystem::PostRequest(FileHandle &handle, string
 	auto headers = create_s3_header(parsed_s3_url.path, http_params, parsed_s3_url.host, "s3", "POST", auth_params, "",
 	                                "", payload_hash, "application/octet-stream");
 
-	return HTTPFileSystem::PostRequest(handle, http_url, headers, buffer_out, buffer_out_len, buffer_in, buffer_in_len);
+	return HTTPFileSystem::PostRequest(handle, http_url, headers, result, buffer_in, buffer_in_len);
 }
 
-unique_ptr<ResponseWrapper> S3FileSystem::PutRequest(FileHandle &handle, string url, HeaderMap header_map,
+unique_ptr<HTTPResponse> S3FileSystem::PutRequest(FileHandle &handle, string url, HTTPHeaders header_map,
                                                      char *buffer_in, idx_t buffer_in_len, string http_params) {
 	auto auth_params = handle.Cast<S3FileHandle>().auth_params;
 	auto parsed_s3_url = S3UrlParse(url, auth_params);
@@ -678,7 +661,7 @@ unique_ptr<ResponseWrapper> S3FileSystem::PutRequest(FileHandle &handle, string
 	return HTTPFileSystem::PutRequest(handle, http_url, headers, buffer_in, buffer_in_len);
 }
 
-unique_ptr<ResponseWrapper> S3FileSystem::HeadRequest(FileHandle &handle, string s3_url, HeaderMap header_map) {
+unique_ptr<HTTPResponse> S3FileSystem::HeadRequest(FileHandle &handle, string s3_url, HTTPHeaders header_map) {
 	auto auth_params = handle.Cast<S3FileHandle>().auth_params;
 	auto parsed_s3_url = S3UrlParse(s3_url, auth_params);
 	string http_url = parsed_s3_url.GetHTTPUrl(auth_params);
@@ -687,7 +670,7 @@ unique_ptr<ResponseWrapper> S3FileSystem::HeadRequest(FileHandle &handle, string
 	return HTTPFileSystem::HeadRequest(handle, http_url, headers);
 }
 
-unique_ptr<ResponseWrapper> S3FileSystem::GetRequest(FileHandle &handle, string s3_url, HeaderMap header_map) {
+unique_ptr<HTTPResponse> S3FileSystem::GetRequest(FileHandle &handle, string s3_url, HTTPHeaders header_map) {
 	auto auth_params = handle.Cast<S3FileHandle>().auth_params;
 	auto parsed_s3_url = S3UrlParse(s3_url, auth_params);
 	string http_url = parsed_s3_url.GetHTTPUrl(auth_params);
@@ -696,7 +679,7 @@ unique_ptr<ResponseWrapper> S3FileSystem::GetRequest(FileHandle &handle, string
 	return HTTPFileSystem::GetRequest(handle, http_url, headers);
 }
 
-unique_ptr<ResponseWrapper> S3FileSystem::GetRangeRequest(FileHandle &handle, string s3_url, HeaderMap header_map,
+unique_ptr<HTTPResponse> S3FileSystem::GetRangeRequest(FileHandle &handle, string s3_url, HTTPHeaders header_map,
                                                           idx_t file_offset, char *buffer_out, idx_t buffer_out_len) {
 	auto auth_params = handle.Cast<S3FileHandle>().auth_params;
 	auto parsed_s3_url = S3UrlParse(s3_url, auth_params);
@@ -706,7 +689,7 @@ unique_ptr<ResponseWrapper> S3FileSystem::GetRangeRequest(FileHandle &handle, st
 	return HTTPFileSystem::GetRangeRequest(handle, http_url, headers, file_offset, buffer_out, buffer_out_len);
 }
 
-unique_ptr<ResponseWrapper> S3FileSystem::DeleteRequest(FileHandle &handle, string s3_url, HeaderMap header_map) {
+unique_ptr<HTTPResponse> S3FileSystem::DeleteRequest(FileHandle &handle, string s3_url, HTTPHeaders header_map) {
 	auto auth_params = handle.Cast<S3FileHandle>().auth_params;
 	auto parsed_s3_url = S3UrlParse(s3_url, auth_params);
 	string http_url = parsed_s3_url.GetHTTPUrl(auth_params);
@@ -724,104 +707,10 @@ unique_ptr<HTTPFileHandle> S3FileSystem::CreateHandle(const OpenFileInfo &file,
 	auto parsed_s3_url = S3UrlParse(file.path, auth_params);
 	ReadQueryParams(parsed_s3_url.query_param, auth_params);
 
-	return duckdb::make_uniq<S3FileHandle>(*this, file, flags, HTTPParams::ReadFrom(opener, info), auth_params,
+	return duckdb::make_uniq<S3FileHandle>(*this, file, flags, HTTPFSParams::ReadFrom(opener, info), auth_params,
 	                                       S3ConfigParams::ReadFrom(opener));
 }
 
-// this computes the signature from https://czak.pl/2015/09/15/s3-rest-api-with-curl.html
-void S3FileSystem::Verify() {
-	S3AuthParams auth_params;
-	auth_params.region = "us-east-1";
-	auth_params.access_key_id = "AKIAIOSFODNN7EXAMPLE";
-	auth_params.secret_access_key = "wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY";
-
-	auto test_header = create_s3_header("/", "", "my-precious-bucket.s3.amazonaws.com", "s3", "GET", auth_params,
-	                                    "20150915", "20150915T124500Z");
-	if (test_header["Authorization"] !=
-	    "AWS4-HMAC-SHA256 Credential=AKIAIOSFODNN7EXAMPLE/20150915/us-east-1/s3/aws4_request, "
-	    "SignedHeaders=host;x-amz-content-sha256;x-amz-date, "
-	    "Signature=182072eb53d85c36b2d791a1fa46a12d23454ec1e921b02075c23aee40166d5a") {
-		throw std::runtime_error("test fail");
-	}
-
-	if (UrlEncode("/category=Books/") != "/category%3DBooks/") {
-		throw std::runtime_error("test fail");
-	}
-	if (UrlEncode("/?category=Books&title=Ducks Retreat/") != "/%3Fcategory%3DBooks%26title%3DDucks%20Retreat/") {
-		throw std::runtime_error("test fail");
-	}
-	if (UrlEncode("/?category=Books&title=Ducks Retreat/", true) !=
-	    "%2F%3Fcategory%3DBooks%26title%3DDucks%20Retreat%2F") {
-		throw std::runtime_error("test fail");
-	}
-	// AWS_SECRET_ACCESS_KEY="vs1BZPxSL2qVARBSg5vCMKJsavCoEPlo/HSHRaVe" AWS_ACCESS_KEY_ID="ASIAYSPIOYDTHTBIITVC"
-	// AWS_SESSION_TOKEN="IQoJb3JpZ2luX2VjENX//////////wEaCWV1LXdlc3QtMSJHMEUCIQDfjzs9BYHrEXDMU/NR+PHV1uSTr7CSVSQdjKSfiPRLdgIgCCztF0VMbi9+uHHAfBVKhV4t9MlUrQg3VAOIsLxrWyoqlAIIHRAAGgw1ODk0MzQ4OTY2MTQiDOGl2DsYxENcKCbh+irxARe91faI+hwUhT60sMGRFg0GWefKnPclH4uRFzczrDOcJlAAaQRJ7KOsT8BrJlrY1jSgjkO7PkVjPp92vi6lJX77bg99MkUTJActiOKmd84XvAE5bFc/jFbqechtBjXzopAPkKsGuaqAhCenXnFt6cwq+LZikv/NJGVw7TRphLV+Aq9PSL9XwdzIgsW2qXwe1c3rxDNj53yStRZHVggdxJ0OgHx5v040c98gFphzSULHyg0OY6wmCMTYcswpb4kO2IIi6AiD9cY25TlwPKRKPi5CdBsTPnyTeW62u7PvwK0fTSy4ZuJUuGKQnH2cKmCXquEwoOHEiQY6nQH9fzY/EDGHMRxWWhxu0HiqIfsuFqC7GS0p0ToKQE+pzNsvVwMjZc+KILIDDQpdCWRIwu53I5PZy2Cvk+3y4XLvdZKQCsAKqeOc4c94UAS4NmUT7mCDOuRV0cLBVM8F0JYBGrUxyI+YoIvHhQWmnRLuKgTb5PkF7ZWrXBHFWG5/tZDOvBbbaCWTlRCL9b0Vpg5+BM/81xd8jChP4w83"
-	// aws --region eu-west-1 --debug s3 ls my-precious-bucket 2>&1 | less
-	string canonical_query_string = "delimiter=%2F&encoding-type=url&list-type=2&prefix="; // aws s3 ls <bucket>
-
-	S3AuthParams auth_params2;
-	auth_params2.region = "eu-west-1";
-	auth_params2.access_key_id = "ASIAYSPIOYDTHTBIITVC";
-	auth_params2.secret_access_key = "vs1BZPxSL2qVARBSg5vCMKJsavCoEPlo/HSHRaVe";
-	auth_params2.session_token =
-	    "IQoJb3JpZ2luX2VjENX//////////wEaCWV1LXdlc3QtMSJHMEUCIQDfjzs9BYHrEXDMU/"
-	    "NR+PHV1uSTr7CSVSQdjKSfiPRLdgIgCCztF0VMbi9+"
-	    "uHHAfBVKhV4t9MlUrQg3VAOIsLxrWyoqlAIIHRAAGgw1ODk0MzQ4OTY2MTQiDOGl2DsYxENcKCbh+irxARe91faI+"
-	    "hwUhT60sMGRFg0GWefKnPclH4uRFzczrDOcJlAAaQRJ7KOsT8BrJlrY1jSgjkO7PkVjPp92vi6lJX77bg99MkUTJA"
-	    "ctiOKmd84XvAE5bFc/jFbqechtBjXzopAPkKsGuaqAhCenXnFt6cwq+LZikv/"
-	    "NJGVw7TRphLV+"
-	    "Aq9PSL9XwdzIgsW2qXwe1c3rxDNj53yStRZHVggdxJ0OgHx5v040c98gFphzSULHyg0OY6wmCMTYcswpb4kO2IIi6"
-	    "AiD9cY25TlwPKRKPi5CdBsTPnyTeW62u7PvwK0fTSy4ZuJUuGKQnH2cKmCXquEwoOHEiQY6nQH9fzY/"
-	    "EDGHMRxWWhxu0HiqIfsuFqC7GS0p0ToKQE+pzNsvVwMjZc+KILIDDQpdCWRIwu53I5PZy2Cvk+"
-	    "3y4XLvdZKQCsAKqeOc4c94UAS4NmUT7mCDOuRV0cLBVM8F0JYBGrUxyI+"
-	    "YoIvHhQWmnRLuKgTb5PkF7ZWrXBHFWG5/tZDOvBbbaCWTlRCL9b0Vpg5+BM/81xd8jChP4w83";
-
-	auto test_header2 = create_s3_header("/", canonical_query_string, "my-precious-bucket.s3.eu-west-1.amazonaws.com",
-	                                     "s3", "GET", auth_params2, "20210904", "20210904T121746Z");
-	if (test_header2["Authorization"] !=
-	    "AWS4-HMAC-SHA256 Credential=ASIAYSPIOYDTHTBIITVC/20210904/eu-west-1/s3/aws4_request, "
-	    "SignedHeaders=host;x-amz-content-sha256;x-amz-date;x-amz-security-token, "
-	    "Signature=4d9d6b59d7836b6485f6ad822de97be40287da30347d83042ea7fbed530dc4c0") {
-		throw std::runtime_error("test fail");
-	}
-
-	S3AuthParams auth_params3;
-	auth_params3.region = "eu-west-1";
-	auth_params3.access_key_id = "S3RVER";
-	auth_params3.secret_access_key = "S3RVER";
-
-	auto test_header3 =
-	    create_s3_header("/correct_auth_test.csv", "", "test-bucket-ceiveran.s3.amazonaws.com", "s3", "PUT",
-	                     auth_params3, "20220121", "20220121T141452Z",
-	                     "28a0cf6ac5c4cb73793091fe6ecc6a68bf90855ac9186158748158f50241bb0c", "text/data;charset=utf-8");
-	if (test_header3["Authorization"] != "AWS4-HMAC-SHA256 Credential=S3RVER/20220121/eu-west-1/s3/aws4_request, "
-	                                     "SignedHeaders=content-type;host;x-amz-content-sha256;x-amz-date, "
-	                                     "Signature=5d9a6cbfaa78a6d0f2ab7df0445e2f1cc9c80cd3655ac7de9e7219c036f23f02") {
-		throw std::runtime_error("test3 fail");
-	}
-
-	// bug #4082
-	S3AuthParams auth_params4;
-	auth_params4.region = "auto";
-	auth_params4.access_key_id = "asdf";
-	auth_params4.secret_access_key = "asdfasdfasdfasdfasdfasdfasdfasdfasdfasdfasdfasdfasdfasdfasdfasdfasdf";
-	create_s3_header("/", "", "exampple.com", "s3", "GET", auth_params4);
-
-	if (UrlEncode("/category=Books/") != "/category%3DBooks/") {
-		throw std::runtime_error("test fail");
-	}
-	if (UrlEncode("/?category=Books&title=Ducks Retreat/") != "/%3Fcategory%3DBooks%26title%3DDucks%20Retreat/") {
-		throw std::runtime_error("test fail");
-	}
-	if (UrlEncode("/?category=Books&title=Ducks Retreat/", true) !=
-	    "%2F%3Fcategory%3DBooks%26title%3DDucks%20Retreat%2F") {
-		throw std::runtime_error("test fail");
-	}
-
-	// TODO add a test that checks the signing for path-style
-}
-
-
 void S3FileHandle::Initialize(optional_ptr<FileOpener> opener) {
 	try {
 		HTTPFileHandle::Initialize(opener);
@@ -883,8 +772,8 @@ void S3FileSystem::RemoveFile(const string &path, optional_ptr<FileOpener> opene
 
 	auto &s3fh = handle->Cast<S3FileHandle>();
 	auto res = DeleteRequest(*handle, s3fh.path, {});
-	if (res->code != 200 && res->code != 204) {
-		throw IOException("Could not remove file \"%s\": %s", {{"errno", to_string(res->code)}}, path, res->error);
+	if (res->status != HTTPStatusCode::OK_200 && res->status != HTTPStatusCode::NoContent_204) {
+		throw IOException("Could not remove file \"%s\": %s", {{"errno", to_string(static_cast<int>(res->status))}}, path, res->GetError());
 	}
 }
 
@@ -998,7 +887,7 @@ vector<OpenFileInfo> S3FileSystem::Glob(const string &glob_pattern, FileOpener *
 	}
 
 	string shared_path = parsed_glob_url.substr(0, first_wildcard_pos);
-	auto http_params = HTTPParams::ReadFrom(opener, info);
+	auto http_params = HTTPFSParams::ReadFrom(opener, info);
 
 	ReadQueryParams(parsed_s3_url.query_param, s3_auth_params);
 
@@ -1076,7 +965,7 @@ bool S3FileSystem::ListFiles(const string &directory, const std::function<void(c
 	return true;
 }
 
-string AWSListObjectV2::Request(string &path, HTTPParams &http_params, S3AuthParams &s3_auth_params,
+string AWSListObjectV2::Request(string &path, HTTPFSParams &http_params, S3AuthParams &s3_auth_params,
                                 string &continuation_token, optional_ptr<HTTPState> state, bool use_delimiter) {
 	auto parsed_url = S3FileSystem::S3UrlParse(path, s3_auth_params);
 
@@ -1099,31 +988,24 @@ string AWSListObjectV2::Request(string &path, HTTPParams &http_params, S3AuthPar
 
 	auto header_map =
 	    create_s3_header(req_path, req_params, parsed_url.host, "s3", "GET", s3_auth_params, "", "", "", "");
-	auto headers = initialize_http_headers(header_map);
 
-	auto client = S3FileSystem::GetClient(http_params, (parsed_url.http_proto + parsed_url.host).c_str(),
-	                                      nullptr); // Get requests use fresh connection
+	// Get requests use fresh connection
+	auto client = http_params.http_util->InitializeClient(http_params, parsed_url.http_proto + parsed_url.host);
 	std::stringstream response;
-	auto res = client->Get(
-	    listobjectv2_url.c_str(), *headers,
-	    [&](const duckdb_httplib_openssl::Response &response) {
-		    if (response.status >= 400) {
+	GetRequestInfo get_request(parsed_url.host, listobjectv2_url, header_map, http_params,
+	    [&](const HTTPResponse &response) {
+		    if (static_cast<int>(response.status) >= 400) {
 			    throw HTTPException(response, "HTTP GET error on '%s' (HTTP %d)", listobjectv2_url, response.status);
 		    }
 		    return true;
 	    },
-	    [&](const char *data, size_t data_length) {
-		    if (state) {
-			    state->total_bytes_received += data_length;
-		    }
-		    response << string(data, data_length);
+	    [&](const_data_ptr_t data, idx_t data_length) {
+		    response << string(const_char_ptr_cast(data), data_length);
 		    return true;
 	    });
-	if (state) {
-		state->get_count++;
-	}
-	if (res.error() != duckdb_httplib_openssl::Error::Success) {
-		throw IOException(to_string(res.error()) + " error for HTTP GET to '" + listobjectv2_url + "'");
+	auto result = http_params.http_util->Request(get_request);
+	if (result->HasRequestError()) {
+		throw IOException("%s error for HTTP GET to '%s'", result->GetRequestError(), listobjectv2_url);
 	}
 
 	return response.str();
diff --git a/extension_config.cmake b/extension_config.cmake
index fa40820..5881043 100644
--- a/extension_config.cmake
+++ b/extension_config.cmake
@@ -8,6 +8,9 @@ else ()
     set(LOAD_HTTPFS_TESTS "")
 endif()
 
+duckdb_extension_load(json)
+duckdb_extension_load(parquet)
+
 duckdb_extension_load(httpfs
 	SOURCE_DIR ${CMAKE_CURRENT_LIST_DIR}
 	INCLUDE_DIR ${CMAKE_CURRENT_LIST_DIR}/extension/httpfs/include
